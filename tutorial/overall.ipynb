{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "A freshman-friendly tutorial for Ark platform.\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Why Ark?\n",
    "\n",
    "Ark is a platform that supports multiple kinds of models running.\n",
    "\n",
    "### Productions\n",
    "\n",
    "Productions in ARK, including models, agents and something else.\n",
    "\n",
    "### Rodemap\n",
    "\n",
    "Rodemap and primary changelog of Ark.\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Installation\n",
    "\n",
    "Install Ark SDK from Github repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://githubfast.com/LotsoTeddy/ArkIntelligence.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication\n",
    "\n",
    "Go to https://www.example.com to generate your API key, and set it in your code or environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"ARK_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart\n",
    "\n",
    "You can chat with a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm Doubao, an AI developed by ByteDance. I can answer a wide variety of questions, from history and science to daily trivia, and have in - depth conversations with you. Whether you need help with knowledge learning, text generation, or just want to chat, I'm here to assist! \""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from arkintelligence.model import ArkModel\n",
    "\n",
    "model = ArkModel(model=\"doubao-1.5-pro-32k-250115\")\n",
    "\n",
    "response = model.chat(prompt=\"Who are you?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you can create a Translator agent to translate your text from English to Chinese:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ÊøÄÂèëÂàõÊÑèÔºå‰∏∞ÂØåÁîüÊ¥ªÔºÅ'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from arkintelligence.agent import ArkAgent\n",
    "\n",
    "agent = ArkAgent(\n",
    "    name=\"Translator\",\n",
    "    model=\"doubao-1.5-pro-32k-250115\",\n",
    "    prompt=\"Translate the input text from English to Chinese.\",\n",
    ")\n",
    "\n",
    "res = agent.run(\"Inspire Creativity, Enrich Life!\")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic usage\n",
    "\n",
    "## Overview\n",
    "\n",
    "The entire list of model ID can be found [here](). The capabilities of each model is listed as follows:\n",
    "\n",
    "| Model ID      | Image understanding | Video generation | Function calling | \n",
    "| - | - | - | - |\n",
    "| doubao-1.5-vision-pro-32k-250115 | ‚úÖ | | |\n",
    "| doubao-seaweed-241128 | | ‚úÖ | |\n",
    "\n",
    "## Text capabilities\n",
    "\n",
    "### Chat\n",
    "\n",
    "Single-turn completion has no memory, so the previous user chat will not stored during chat. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got it! My name is ArkIntelligence. From now on, you can call me by this name whenever you interact with me. \n",
      "My name is Doubao. Nice to meet you!\n"
     ]
    }
   ],
   "source": [
    "from arkintelligence.model import ArkModel\n",
    "\n",
    "model = ArkModel(model=\"doubao-1.5-pro-32k-250115\")\n",
    "\n",
    "response = model.chat(prompt=\"Your name is ArkIntelligence.\")\n",
    "print(response + '\\n')\n",
    "\n",
    "response = model.chat(prompt=\"What is your name?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat with memory\n",
    "\n",
    "Multi-turn chat has memory, the model can remember the history messages by setting `enable_context=True` during initialization. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for naming me ArkIntelligence. From now on, I'll answer your questions and have conversations with you under this name. If you have any queries, just tell me! \n",
      "My name is ArkIntelligence. I'm here to assist you with any questions you might have. \n"
     ]
    }
   ],
   "source": [
    "from arkintelligence.model import ArkModel\n",
    "\n",
    "model = ArkModel(\n",
    "    model=\"doubao-1.5-pro-32k-250115\",\n",
    "    enbale_context=True # Make LLM remember the context\n",
    "    )\n",
    "\n",
    "response = model.chat(prompt=\"Your name is ArkIntelligence.\")\n",
    "print(response + '\\n')\n",
    "\n",
    "response = model.chat(prompt=\"What is your name?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can remember the previous user input.\n",
    "\n",
    "### Chat with attachment\n",
    "\n",
    "We support upload your single file with format of `.txt`, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkintelligence.model import ArkModel\n",
    "\n",
    "model = ArkModel(model=\"doubao-1.5-pro-32k-250115\")\n",
    "\n",
    "response = model.chat(\n",
    "    prompt=\"Your name is ArkIntelligence.\",\n",
    "    attachment=\"FILE_PATH\",  # TODO(LotsoTeddy): Parsing attachment\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision capabilities\n",
    "\n",
    "Ark provides capabilities about multi-media, such as vision and sounds. Here we introduce the vision-related demos.\n",
    "\n",
    "### Image understanding\n",
    "\n",
    "We use LLM to understand the following image:\n",
    "\n",
    "<img src='https://ark-tutorial.tos-cn-beijing.volces.com/assets/images/cat.png' style='width:150px'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This is a close - up photograph of an adorable cat. The cat has a soft, plush coat in a light grayish - beige color. Its fur appears very well - groomed and smooth. The cat's most striking feature is its large, round eyes that are a dark, almost black color, giving it an expression of wide - eyed curiosity or surprise. Its ears are upright and have a light pink interior, adding a touch of contrast to its overall appearance.\\n\\nThe cat's nose is a small, delicate pink, and its whiskers are long, white, and prominent, extending outward from its cheeks. It is lying down on a light - colored surface, possibly a carpet or a mat, with its front paws stretched out in front of it.\\n\\nIn the background, the setting seems to be indoors. There are some indistinct objects, including what looks like part of a piece of furniture, perhaps a chair or a cabinet, and some other household items that are out of focus, ensuring that the cat remains the central subject of the image. The overall atmosphere of the picture is warm and cozy, highlighting the cat's cute and endearing qualities. \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from arkintelligence.model import ArkModel\n",
    "\n",
    "IMAGE_PATH = \"./assets/images/cat.png\"\n",
    "model = ArkModel(\n",
    "    model=\"doubao-1.5-vision-pro-32k-250115\",  # Use vision model here\n",
    ")\n",
    "\n",
    "response = model.process_image(\n",
    "    prompt=\"Please describe this image with details.\",\n",
    "    attachment=IMAGE_PATH,\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video generation\n",
    "\n",
    "We use `doubao` model to generate a video according to a static image and prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REF_IMAGE_PATH = \"./assets/images/cat.png\"\n",
    "model = ArkModel(\n",
    "    model=\"doubao-seaweed-241128\",  # Use video generation model here\n",
    ")\n",
    "\n",
    "response = model.generate_video(\n",
    "    prompt=\"Please generate a video with a cat running.\",\n",
    "    attachment=REF_IMAGE_PATH,\n",
    ") # This will take a while\n",
    "\n",
    "print(\"Waiting for video generation...\")\n",
    "print(\"Generated video url is: \" + response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> Want to make the video more vivid? Maybe you need: prompt refine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent\n",
    "\n",
    "## A minimal agent\n",
    "\n",
    "A simple agent can be built with several lines. The `name` field is not necessary, but provide it will make agent more intelligent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkintelligence.agent import ArkAgent\n",
    "\n",
    "agent = ArkAgent(\n",
    "    name=\"Meeting assistant\",\n",
    "    model=\"deepseek-v3-250324\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can chat with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm your **Meeting Assistant**, here to help you with anything related to meetings‚Äîwhether it's scheduling, note-taking, summarizing discussions, setting agendas, or following up on action items.  \\n\\nHow can I assist you today? üòä\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent.run(\"Who are you?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A complex agent with several capabilities (such as knowledge base and function calling) just needs more 2 lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduce what the agent is.\n",
    "\n",
    "## Prompt engineering\n",
    "\n",
    "Prompt engineering is important that can make your prompt more rich and useful for models.\n",
    "\n",
    "### Prompt usage\n",
    "\n",
    "Prompt can be used for interacting with models. The models understand your prompt and give responses. For example, with a prompt, a complex English statement can be optimized to be more concise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Please provide the sentence, and I'll do my best to make it more concise and elegant.\n",
      "In Chinese houses, the kitchen serves solely for cooking. However, in many Western homes, it's not just a cooking and dining area but also a gathering place for family and friends. \n"
     ]
    }
   ],
   "source": [
    "from arkintelligence.model import ArkModel\n",
    "\n",
    "model = ArkModel(\n",
    "    model=\"doubao-1.5-pro-32k-250115\",\n",
    "    enbale_context=True,\n",
    ")\n",
    "\n",
    "response = model.chat(\n",
    "    prompt=\"I will give you a sentence, please make the sentence more concise and elegant.\"\n",
    ")\n",
    "print(response + '\\n')\n",
    "\n",
    "response = model.chat(\n",
    "    prompt=\"In a Chinese house, the kitchen is only a place for cooking things; but in many Western houses, the kitchen is not only a place where people cook meals and eat them but also a place where the family members or friends usually meet each other.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt refine\n",
    "\n",
    "Refine prompts is important, the comparision is as follows. We use a simple and a refined prompt to generate images, then compare the image quality.\n",
    "\n",
    "You can build an agent to refine prompt: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prompt:\n",
      "Draw a cute golden british shorthair cat.\n",
      "Refined prompt:\n",
      "Create an image of an adorable Golden British Shorthair cat. Focus on the cat's round face, big, bright eyes, short and plush fur with a warm golden hue. Include details like the cat's small, rounded ears, a slightly chubby body, and its soft paws. The cat could be in a relaxed pose, perhaps sitting or lying down, with an expression that exudes cuteness and charm. Consider adding a simple, cozy background like a soft blanket or a sunny corner of a room to enhance the overall appealing and endearing atmosphere. \n"
     ]
    }
   ],
   "source": [
    "from arkintelligence.agent import ArkAgent\n",
    "\n",
    "prompt = \"Draw a cute golden british shorthair cat.\"\n",
    "\n",
    "refine_agent = ArkAgent(\n",
    "    name=\"Prompt refine assistant\",\n",
    "    model=\"doubao-1-5-pro-256k-250115\",\n",
    "    prompt=\"Refine the prompt to make it more suitable for image generation.\",\n",
    ")\n",
    "prompt_refined = refine_agent.run(prompt)\n",
    "\n",
    "print(f\"Original prompt:\\n{prompt}\")\n",
    "print(f\"Refined prompt:\\n{prompt_refined}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the two prompts to generate videos and see the differents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkintelligence.model import ArkModel\n",
    "\n",
    "model = ArkModel(\n",
    "    model=\"doubao-seaweed-241128\",  # Use video generation model here\n",
    ")\n",
    "\n",
    "video = model.generate_video(\n",
    "    prompt=prompt,\n",
    ")\n",
    "video_with_refine = model.generate_video(\n",
    "    prompt=prompt_refined,\n",
    ")\n",
    "\n",
    "print(f'Original video url is: {video}')\n",
    "print(f'Refined video url is: {video_with_refine}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equip to agent\n",
    "\n",
    "You can enable prompt refine in your agent, the agent will automatically refine your **first** prompt with a default refine prompt (you can modify this by pass `refine_prompt`). The usage is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkintelligence.agent import ArkAgent\n",
    "\n",
    "prompt = \"Draw a cute golden british shorthair cat.\"\n",
    "\n",
    "refine_agent = ArkAgent(\n",
    "    name=\"Prompt refine assistant\",\n",
    "    model=\"doubao-1-5-pro-256k-250115\",\n",
    "    prompt=\"Refine the prompt to make it more suitable for image generation.\",\n",
    "    refine_requirement=\"Refine the prompt to make it more suitable for image generation.\",\n",
    ")\n",
    "prompt_refined = refine_agent.run(prompt)\n",
    "\n",
    "print(f\"Original prompt:\\n{prompt}\")\n",
    "print(f\"Refined prompt:\\n{prompt_refined}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function calling\n",
    "\n",
    "The Ark agent can call your local function to finish your task.\n",
    "\n",
    "### Tool\n",
    "\n",
    "Before init an agent, you should create a tool (which is a Python function) to define tool logic. For example, we provide a `visit_url` here to read the website information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkintelligence.tool import ArkTool\n",
    "\n",
    "@ArkTool\n",
    "def visit_url(url: str):\n",
    "    \"\"\"Visit a URL and return the content.\n",
    "    \n",
    "    Long description of the function.\n",
    "    \n",
    "    Args:\n",
    "        url (str): The URL to visit.\n",
    "        \n",
    "    Returns:\n",
    "        str: The content of the URL.\n",
    "    \"\"\"\n",
    "    import requests\n",
    "\n",
    "    response = requests.get(url)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function can be decorated by `ArkTool` to be a tool, which can be invoked by Ark agent. The docstring of function is important, as its name, description and arguments will be sent to the model. The detailed docstring usage can be found [here]().\n",
    "\n",
    "### Equip to agent\n",
    "\n",
    "The created tool can be equipped to an agent with just only one option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkintelligence.agent import ArkAgent\n",
    "\n",
    "agent = ArkAgent(\n",
    "    name=\"Web search assistant\",\n",
    "    model=\"doubao-1-5-pro-256k-250115\",\n",
    "    tools=['visit_url'],\n",
    ")\n",
    "\n",
    "response = agent.run(\"What is the latest news about ArkIntelligence?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG\n",
    "\n",
    "RAG enhances model response. In Ark, we provide concise method to enbale RAG.\n",
    "\n",
    "### Knowledge base\n",
    "\n",
    "You can create a knowledge base with your local files like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkintelligence.knowledgebase import ArkKnowledgeBase\n",
    "\n",
    "kb = ArkKnowledgeBase(\n",
    "    name=\"ArkIntelligence\",\n",
    "    description=\"ArkIntelligence is a company that provides AI solutions.\",\n",
    "    data=data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During creation, your data will be uploaded to Ark platform and processed by embedding models such as `doubao-embed` (embed model API can be found [here]()). The processed data is stored in your local memory rather than cloud space.\n",
    "\n",
    "### Equip to agent\n",
    "\n",
    "Equip the knowledge base to your agent like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ArkAgent(\n",
    "    name=\"Knowledge base agent\",\n",
    "    model=\"deepseek-v3-250324\",\n",
    "    prompt=\"You are a helpful assistant.\",\n",
    "    knowldgebase=kb,\n",
    ")\n",
    "res = agent.run(\"Summary the pros and cons of SmartVM\")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Awesome samples\n",
    "\n",
    "## Auto-summary\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arkintelligence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
