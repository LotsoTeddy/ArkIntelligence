{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LotsoTeddy/ArkIntelligence/blob/tutorial/tutorial/overall.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG33oR-V0u25"
      },
      "source": [
        "<hr/>\n",
        "<img src=\"https://portal.volccdn.com/obj/volcfe/logo/appbar_logo_dark.2.svg?sanitize=true\" align=center>\n",
        "<hr/>\n",
        "\n",
        "# 🎉 Introduction\n",
        "---\n",
        "\n",
        "Volengine Ark provides you with a development platform for large model services, offering feature-rich, secure and price-competitive model calling services, as well as end-to-end functions such as model data, fine-tuning, reasoning, evaluation, and so on, to comprehensively guarantee your AI application development landing.\n",
        "\n",
        "This is a freshman-friendly tutorial for Ark SDK, which helps you to build your own intelligent applications through agent, knowledge base, and so on.\n",
        "\n",
        "**Github**\n",
        "\n",
        "Click [here](https://github.com/LotsoTeddy/ArkIntelligence/) to explore the Work-In-Progress Github repository.\n",
        "\n",
        "**NOTE**\n",
        "- 🟡 This tutorial updates in `tutorial` branch.\n",
        "- ❗ The ArkIntelligence is experimental and exists protential bugs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ4wkrB4Hrr4"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iveInZ44HruU"
      },
      "source": [
        "### Why Ark?\n",
        "\n",
        "Ark is a platform that supports multiple kinds of models running. Ark has the following advantages:\n",
        "\n",
        "- **Security and Mutual Trust**: Large model security and trust program strictly protects the model and information security of model providers and model users, click to view the white paper on security and mutual trust.\n",
        "- **Selected Models**: Supporting multi-industry models for various business scenarios, providing rich platform applications and tools to help you build your own innovative scenarios.\n",
        "- **Strong Arithmetic Power**: Based on the volcano's Wanka resource pool, we provide sufficient high-performance GPU resources to provide you with end-to-end modeling services including model fine-tuning, evaluation, and inference.\n",
        "- **Enterprise-level services**: provide professional service system support, professional product operation and sales delivery services to meet the needs of enterprise application construction and delivery."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDoc86MlHr1M"
      },
      "source": [
        "### Productions\n",
        "\n",
        "Productions in ARK, including models, agents and something else. The specific productions are shown in the following image.\n",
        "\n",
        "![productions](https://ark-tutorial.tos-cn-beijing.volces.com/assets/images/productions.png)\n",
        "\n",
        "Rodemap and primary changelog of Ark.\n",
        "\n",
        "| Date | Change log |\n",
        "| :--- | :--- |\n",
        "| 2025-04-02 | Tutorial released |\n",
        "| 2025-04-01 | ArkIntelligence released |\n",
        "| 2025-03-29 | Prepare |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3EFGnfhHr3s"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnUjrM_NHr51"
      },
      "source": [
        "### Installation\n",
        "\n",
        "Install ArkIntelligence SDK from Github repository. This may take more than 1 minute in Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0T9598P80u26",
        "outputId": "45c02fe3-336a-440e-d56c-5334d2b40792",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/LotsoTeddy/ArkIntelligence.git\n",
            "  Cloning https://github.com/LotsoTeddy/ArkIntelligence.git to /tmp/pip-req-build-zglc9jy3\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/LotsoTeddy/ArkIntelligence.git /tmp/pip-req-build-zglc9jy3\n",
            "  Resolved https://github.com/LotsoTeddy/ArkIntelligence.git to commit 729f0e7f0ad80ff18170cabfc2e0e51dd2dabeeb\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ArkIntelligence==1.0.0) (2.32.3)\n",
            "Requirement already satisfied: openai>=1.0 in /usr/local/lib/python3.11/dist-packages (from ArkIntelligence==1.0.0) (1.69.0)\n",
            "Requirement already satisfied: docstring_parser in /usr/local/lib/python3.11/dist-packages (from ArkIntelligence==1.0.0) (0.16)\n",
            "Requirement already satisfied: volcengine in /usr/local/lib/python3.11/dist-packages (from ArkIntelligence==1.0.0) (1.0.179)\n",
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (from ArkIntelligence==1.0.0) (0.12.28)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.11/dist-packages (from ArkIntelligence==1.0.0) (0.7.3)\n",
            "Requirement already satisfied: volcengine-python-sdk[ark] in /usr/local/lib/python3.11/dist-packages (from ArkIntelligence==1.0.0) (1.1.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0->ArkIntelligence==1.0.0) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0->ArkIntelligence==1.0.0) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0->ArkIntelligence==1.0.0) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0->ArkIntelligence==1.0.0) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0->ArkIntelligence==1.0.0) (2.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.0->ArkIntelligence==1.0.0) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0->ArkIntelligence==1.0.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0->ArkIntelligence==1.0.0) (4.13.0)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->ArkIntelligence==1.0.0) (0.4.6)\n",
            "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from llama-index->ArkIntelligence==1.0.0) (0.4.1)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.28 in /usr/local/lib/python3.11/dist-packages (from llama-index->ArkIntelligence==1.0.0) (0.12.28)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->ArkIntelligence==1.0.0) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->ArkIntelligence==1.0.0) (0.6.11)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->ArkIntelligence==1.0.0) (0.3.30)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->ArkIntelligence==1.0.0) (0.4.3)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->ArkIntelligence==1.0.0) (0.3.1)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->ArkIntelligence==1.0.0) (0.3.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->ArkIntelligence==1.0.0) (0.4.7)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->ArkIntelligence==1.0.0) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index->ArkIntelligence==1.0.0) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ArkIntelligence==1.0.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->ArkIntelligence==1.0.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->ArkIntelligence==1.0.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->ArkIntelligence==1.0.0) (2025.1.31)\n",
            "Requirement already satisfied: retry==0.9.2 in /usr/local/lib/python3.11/dist-packages (from volcengine->ArkIntelligence==1.0.0) (0.9.2)\n",
            "Requirement already satisfied: pytz==2020.5 in /usr/local/lib/python3.11/dist-packages (from volcengine->ArkIntelligence==1.0.0) (2020.5)\n",
            "Requirement already satisfied: pycryptodome==3.9.9 in /usr/local/lib/python3.11/dist-packages (from volcengine->ArkIntelligence==1.0.0) (3.9.9)\n",
            "Requirement already satisfied: protobuf>=3.18.3 in /usr/local/lib/python3.11/dist-packages (from volcengine->ArkIntelligence==1.0.0) (5.29.4)\n",
            "Requirement already satisfied: google>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from volcengine->ArkIntelligence==1.0.0) (3.0.0)\n",
            "Requirement already satisfied: six>=1.0 in /usr/local/lib/python3.11/dist-packages (from volcengine->ArkIntelligence==1.0.0) (1.17.0)\n",
            "Requirement already satisfied: decorator>=3.4.2 in /usr/local/lib/python3.11/dist-packages (from retry==0.9.2->volcengine->ArkIntelligence==1.0.0) (4.4.2)\n",
            "Requirement already satisfied: py<2.0.0,>=1.4.26 in /usr/local/lib/python3.11/dist-packages (from retry==0.9.2->volcengine->ArkIntelligence==1.0.0) (1.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from volcengine-python-sdk[ark]->ArkIntelligence==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: cryptography<43.0.4,>=43.0.3 in /usr/local/lib/python3.11/dist-packages (from volcengine-python-sdk[ark]->ArkIntelligence==1.0.0) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<43.0.4,>=43.0.3->volcengine-python-sdk[ark]->ArkIntelligence==1.0.0) (1.17.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from google>=3.0.0->volcengine->ArkIntelligence==1.0.0) (4.13.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.0->ArkIntelligence==1.0.0) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0->ArkIntelligence==1.0.0) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (2.0.40)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (3.11.14)\n",
            "Requirement already satisfied: banks<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (2.1.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (2025.3.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (11.1.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (9.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (0.9.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (1.17.2)\n",
            "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.13 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->ArkIntelligence==1.0.0) (0.1.17)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->ArkIntelligence==1.0.0) (2.2.2)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->ArkIntelligence==1.0.0) (5.4.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->ArkIntelligence==1.0.0) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index->ArkIntelligence==1.0.0) (0.6.4.post1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index->ArkIntelligence==1.0.0) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index->ArkIntelligence==1.0.0) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index->ArkIntelligence==1.0.0) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai>=1.0->ArkIntelligence==1.0.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai>=1.0->ArkIntelligence==1.0.0) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai>=1.0->ArkIntelligence==1.0.0) (0.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (1.18.3)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (1.7.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (4.3.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->google>=3.0.0->volcengine->ArkIntelligence==1.0.0) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<43.0.4,>=43.0.3->volcengine-python-sdk[ark]->ArkIntelligence==1.0.0) (2.22)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.4 in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ArkIntelligence==1.0.0) (0.6.9)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (3.26.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->ArkIntelligence==1.0.0) (2025.2)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.4->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ArkIntelligence==1.0.0) (1.1.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (24.2)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.28->llama-index->ArkIntelligence==1.0.0) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/LotsoTeddy/ArkIntelligence.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILGi2_YG0u26"
      },
      "source": [
        "### Authentication"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Typical\n",
        "Go to [this doc](https://www.volcengine.com/docs/82379/1399008#b00dee71) to learn how to generate your API key, and set it in your code or environment variables:"
      ],
      "metadata": {
        "id": "YisLC1NUsWQS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8IXRcOG0u26"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"ARK_API_KEY\"] = \"SET_YOUR_ARK_API_KEY\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Google Colab\n",
        "\n",
        "If you run in Google Colab, you can set your api key by the following method in a more private method:"
      ],
      "metadata": {
        "id": "5LzTBjseaWw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"ARK_API_KEY\"] = userdata.get('ARK_API_KEY')"
      ],
      "metadata": {
        "id": "lIESHAidaewY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quEtH1_k0u26"
      },
      "source": [
        "## Quickstart\n",
        "\n",
        "You can chat with a model to learn the model's information:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdDzL7NZ0u26",
        "outputId": "4942e9c7-3db9-4506-df09-9a0955198fcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: Slogan of Bytedance?\n",
            "A: Bytedance doesn't have a unified, single - fixed slogan globally. However, some concepts and expressions that reflect its values and pursuits can be regarded as guiding ideas similar to slogans:\n",
            "\n",
            "### \"Inspire Creativity, Enrich Life\"\n",
            "This statement reflects Bytedance's mission. The company is committed to providing platforms and tools that empower people to unleash their creativity. Through various products such as TikTok (Douyin in China), people can create and share a wide range of content, including short - videos, music, and artworks. At the same time, by offering diverse and high - quality content, it enriches the lives of users around the world, whether it's for entertainment, learning, or self - expression.   \n"
          ]
        }
      ],
      "source": [
        "from arkintelligence.model import ArkModel\n",
        "\n",
        "model = ArkModel(model=\"doubao-1.5-pro-32k-250115\")\n",
        "\n",
        "prompt = \"Slogan of Bytedance?\" # @param {type:\"string\"}\n",
        "\n",
        "response = model.chat(prompt=prompt)\n",
        "\n",
        "print(f'Q: {prompt}')\n",
        "print(f'A: {response}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzNUWEfS0u27"
      },
      "source": [
        "Furthermore, you can create an agent (named by `Translator`) for translating your text from *English* to *other languages*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-na7hpMK0u27",
        "outputId": "469fd69b-f804-49b0-8c9a-854558cfeebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated text from agent:\n",
            "\n",
            "### Chinese\n",
            "激发创造力，丰富生活！\n",
            "\n",
            "### French\n",
            "Inspirez la créativité, enrichissez la vie !\n",
            "\n",
            "### Japanese\n",
            "創造力を引き出し、生活を豊かに！ \n"
          ]
        }
      ],
      "source": [
        "from arkintelligence.agent import ArkAgent\n",
        "\n",
        "agent = ArkAgent(\n",
        "    name=\"Translator\",\n",
        "    model=\"doubao-1.5-pro-32k-250115\",\n",
        "    prompt=\"Translate the input text from English to Chinese, French, and Japanese.\",\n",
        ")\n",
        "\n",
        "response = agent.run(\"Inspire Creativity, Enrich Life!\")\n",
        "\n",
        "print('Translated text from agent:\\n')\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7XyOQM30u27"
      },
      "source": [
        "# 🛠️ Basic usage\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86v3HcBsIdLf"
      },
      "source": [
        "## Overview\n",
        "\n",
        "The entire list of model ID can be found [here](https://www.volcengine.com/docs/82379/1330310). The capabilities of each model is listed as follows:\n",
        "\n",
        "| Model ID      | Image understanding | Video generation | Function calling |\n",
        "| - | - | - | - |\n",
        "| doubao-1.5-vision-pro-32k-250115 | ✅ | | |\n",
        "| doubao-seaweed-241128 | | ✅ | |\n",
        "| ... | | | |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzm3g2RQGQIh"
      },
      "source": [
        "## Text capabilities\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU_eb9k5GW_-"
      },
      "source": [
        "### Chat\n",
        "\n",
        "A simplest chat is in the form of single-turn, which has no memory. The history messages whether from user or model will not be saved. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgT1DSPH0u27",
        "outputId": "33c77f04-4756-4d57-d949-89bc5c65a60b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1: Your name is ArkIntelligence.\n",
            "A1: Got it! I'm ArkIntelligence, ready to assist you. \n",
            "\n",
            "Q2: Do you remember the last prompt? What is your name?\n",
            "A2: I do remember your last prompt. My name is Doubao.\n"
          ]
        }
      ],
      "source": [
        "from arkintelligence.model import ArkModel\n",
        "\n",
        "\n",
        "prompt1 = \"Your name is ArkIntelligence.\"\n",
        "prompt2 = \"Do you remember the last prompt? What is your name?\"\n",
        "\n",
        "model = ArkModel(model=\"doubao-1.5-pro-32k-250115\")\n",
        "\n",
        "res1 = model.chat(prompt=prompt1)\n",
        "res2 = model.chat(prompt=prompt2)\n",
        "\n",
        "print(f\"Q1: {prompt1}\")\n",
        "print(f\"A1: {res1}\\n\")\n",
        "\n",
        "print(f\"Q2: {prompt2}\")\n",
        "print(f\"A2: {res2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_S5v1-36CT3"
      },
      "source": [
        "In the above code, the first chat sets a name for the model, but this message is not saved, hence the second chat will not return the preset name."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gpFnnfV0u27"
      },
      "source": [
        "### Chat with prefix/session cache\n",
        "\n",
        "Sometimes you need a multiple turn chatting, you can enable history message saving by setting `enable_context=True` during model initialization. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy8IJ2vI0u27",
        "outputId": "0d12aa0d-e695-4ae6-9817-4f7cb7f5a333"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1: Your name is ArkIntelligence.\n",
            "A1: Alright! From now on, my name is ArkIntelligence. Nice to meet you!\n",
            "\n",
            "Q2: Do you remember the last prompt? What is your name?\n",
            "A2: My name is ArkIntelligence. I remember your previous prompt where you told me this name. \n"
          ]
        }
      ],
      "source": [
        "from arkintelligence.model import ArkModel\n",
        "\n",
        "\n",
        "prompt1 = \"Your name is ArkIntelligence.\"\n",
        "prompt2 = \"Do you remember the last prompt? What is your name?\"\n",
        "\n",
        "model = ArkModel(\n",
        "    model=\"doubao-1.5-pro-32k-250115\",\n",
        "    enbale_context=True # Make the model remember the context\n",
        "    )\n",
        "\n",
        "res1 = model.chat(prompt=prompt1)\n",
        "res2 = model.chat(prompt=prompt2)\n",
        "\n",
        "print(f\"Q1: {prompt1}\")\n",
        "print(f\"A1: {res1}\\n\")\n",
        "\n",
        "print(f\"Q2: {prompt2}\")\n",
        "print(f\"A2: {res2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model can remember the previous user inputs. Besides, using prefix and session cache can also:\n",
        "\n",
        "- Performance improvement: make your inference faster\n",
        "- Cost saving: make your token cost less\n",
        "\n",
        "The context will be managed automatically in ArkIntelligence!\n",
        "\n",
        "For more context management API, see [here](https://www.volcengine.com/docs/82379/1346559)."
      ],
      "metadata": {
        "id": "kxRjU8b4qcIK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chat with stream\n",
        "\n",
        "Sometimes, your design to get a long output from model. With stream output, you can get a rapid response without waiting for a long time. The output will be printed gradually:"
      ],
      "metadata": {
        "id": "6TJ2ym7uqcBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from arkintelligence.model import ArkModel\n",
        "\n",
        "model = ArkModel(model=\"doubao-1.5-pro-32k-250115\")\n",
        "\n",
        "response = model.chat(\n",
        "    prompt=\"Please help me to write an introduction of Bytedance with nearly 300 words.\",\n",
        "    stream=True # @param [\"True\", \"False\"] {type:\"raw\"}\n",
        ")"
      ],
      "metadata": {
        "id": "HYP4qhZcrAyY",
        "outputId": "4579445a-1e1e-4cfc-83ce-bced34fe0b24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Bytedance: A Global Tech Powerhouse Revolutionizing Digital Entertainment\n",
            "\n",
            "Bytedance, founded in 2012 by Zhang Yiming, has emerged as a global technology giant, reshaping the digital landscape with its innovative platforms and cutting - edge technologies.\n",
            "\n",
            "At the heart of Bytedance's success are its content - driven products. TikTok, a short - video sharing platform, has taken the world by storm. With its user - friendly interface and a vast library of creative and engaging content, TikTok has amassed billions of users across the globe, becoming a cultural phenomenon. It has given a voice to creators of all ages, enabling them to showcase their talents and connect with a global audience.\n",
            "\n",
            "Another significant offering is Douyin, the Chinese version of TikTok, which is equally popular in the domestic market. It has transformed the way people consume and create entertainment in China.\n",
            "\n",
            "Bytedance also owns news and information platforms like Toutiao, which uses advanced algorithms to deliver personalized news content to users. This approach has revolutionized news consumption, making it more relevant and engaging.\n",
            "\n",
            "In addition to its consumer - facing products, Bytedance is committed to technological research and development. The company invests heavily in artificial intelligence, computer vision, and natural language processing, which underpin the functionality and user experience of its platforms.\n",
            "\n",
            "As it continues to expand its influence globally, Bytedance is at the forefront of driving innovation in the digital entertainment and media industries, with the potential to shape the future of how we interact with digital content. "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The stream-style output is useful in long-text interaction applications. Note that the stream is not supported in agent currently."
      ],
      "metadata": {
        "id": "e9AXQasXGdoE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5ntuS7B0u27"
      },
      "source": [
        "### Chat with attachment [WIP]\n",
        "\n",
        "We support upload your single file with format of `.txt`, for example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwvyrYsV0u27"
      },
      "outputs": [],
      "source": [
        "# ======== [WIP] ========\n",
        "# from arkintelligence.model import ArkModel\n",
        "\n",
        "# model = ArkModel(model=\"doubao-1.5-pro-32k-250115\")\n",
        "\n",
        "# response = model.chat(\n",
        "#     prompt=\"Your name is ArkIntelligence.\",\n",
        "#     attachment=\"FILE_PATH\",  # TODO(LotsoTeddy): Parsing attachment\n",
        "# )\n",
        "# response"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Referenced APIs\n",
        "\n",
        "Some basic links ...\n",
        "\n",
        "-\n",
        "-\n",
        "-"
      ],
      "metadata": {
        "id": "OgpjnvAQXg-0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGIgSZBa0u27"
      },
      "source": [
        "## Vision capabilities\n",
        "\n",
        "Ark provides capabilities about multi-media, such as vision and sounds. Here we introduce the vision-related demos. The vision-related task is devided into image understanding and video generation.\n",
        "\n",
        "- **Image understanding**: this task can read information from one or several images and return the content to the user\n",
        "- **Video generation**: this task can generate video from text and images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULwq7QJhGeae"
      },
      "source": [
        "### Image understanding\n",
        "\n",
        "We use the model `doubao-1.5-vision-pro-32k-250115` to understand the following image:\n",
        "\n",
        "<img src='https://ark-tutorial.tos-cn-beijing.volces.com/assets/images/cat.png' style='width:100px'>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk9lq6bB0u27",
        "outputId": "50873e74-4e2b-4feb-a041-5ef747dfb2f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response from model:\n",
            "\n",
            "This is a close - up photograph of a charming cat. The cat has a soft, light gray coat with subtle darker gray stripes running through it, giving its fur a delicate and textured appearance. Its face is round and endearing, with large, round eyes that are a dark, captivating shade, making the cat look incredibly alert and curious. The cat's nose is small and pink, adding a touch of cuteness to its overall look.\n",
            "\n",
            "Long, white whiskers extend from either side of its muzzle, emphasizing its feline features. The cat's ears are upright and have a light pink inner lining, covered with fine fur. It is lying down on what appears to be a light - colored surface, possibly a carpet or a mat.\n",
            "\n",
            "In the background, there are some indistinct objects. There is a glimpse of what seems to be a piece of furniture, perhaps a chair with a dark backrest, and some other household items that are out of focus, ensuring that the cat remains the central subject of the image. The overall atmosphere of the picture is cozy and intimate, capturing a moment of the cat's relaxed state at home. \n"
          ]
        }
      ],
      "source": [
        "from arkintelligence.model import ArkModel\n",
        "\n",
        "IMAGE_PATH = \"https://ark-tutorial.tos-cn-beijing.volces.com/assets/images/cat.png\"\n",
        "model = ArkModel(\n",
        "    model=\"doubao-1.5-vision-pro-32k-250115\",  # Use vision model here\n",
        ")\n",
        "\n",
        "response = model.process_image(\n",
        "    prompt=\"Please describe this image with details.\",\n",
        "    attachment=IMAGE_PATH,\n",
        ")\n",
        "\n",
        "print('Response from model:\\n')\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kycGTtYd0u27"
      },
      "source": [
        "### Video generation\n",
        "\n",
        "We use `doubao-seaweed-241128` model to generate a video according to a static image and prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC7f0ipR0u27",
        "outputId": "d5a0f822-9d66-4d9b-a6f6-eb0e7859564e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Waiting for video generation, this may take a while...\n",
            "\n",
            "Generated video url: https://ark-content-generation-cn-beijing.tos-cn-beijing.volces.com/doubao-seaweed/doubao-seaweed-2100390175-02174357478596100000000000000000000ffffac15606b93ad78.mp4?X-Tos-Algorithm=TOS4-HMAC-SHA256&X-Tos-Credential=AKLTYjg3ZjNlOGM0YzQyNGE1MmI2MDFiOTM3Y2IwMTY3OTE%2F20250402%2Fcn-beijing%2Ftos%2Frequest&X-Tos-Date=20250402T062038Z&X-Tos-Expires=86400&X-Tos-Signature=d3e06675512df758b34e4e64c10a1ebdcbd32bddaf7e6eb67c29177b46cb7b27&X-Tos-SignedHeaders=host\n"
          ]
        }
      ],
      "source": [
        "REF_IMAGE_PATH = \"https://ark-tutorial.tos-cn-beijing.volces.com/assets/images/cat.png\"\n",
        "model = ArkModel(\n",
        "    model=\"doubao-seaweed-241128\",  # Use video generation model here\n",
        ")\n",
        "\n",
        "response = model.generate_video(\n",
        "    prompt=\"Please generate a video with a cat running.\",\n",
        "    attachment=REF_IMAGE_PATH,\n",
        ")\n",
        "\n",
        "# This may take a while...\n",
        "print(f\"Generated video url: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYcHPock0u27"
      },
      "source": [
        "For more models that support video generation, you can visit [here]().\n",
        "\n",
        "If you want to make the video more vivid, maybe you need: prompt refine."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Referenced APIs\n",
        "\n",
        "Some basic links ...\n",
        "\n",
        "-\n",
        "-\n",
        "-"
      ],
      "metadata": {
        "id": "EM4OsfOZXz71"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqWSml5i0u28"
      },
      "source": [
        "# 🤖 Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta50kBeYKBFM"
      },
      "source": [
        "## A minimal agent\n",
        "\n",
        "A simple agent can be built with several lines. The `name` field is not necessary, but provide it will make agent more intelligent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejpD_lRz0u28"
      },
      "outputs": [],
      "source": [
        "from arkintelligence.agent import ArkAgent\n",
        "\n",
        "agent = ArkAgent(\n",
        "    name=\"Meeting assistant\",\n",
        "    model=\"deepseek-v3-250324\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqEpIpze0u28"
      },
      "source": [
        "Then, you can run it with an input prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cqz2hfXy0u28",
        "outputId": "04883dbc-6a13-4dcb-de75-7190a2fa5d06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi! I'm your **Meeting Assistant**, here to help you with anything related to meetings, scheduling, note-taking, follow-ups, and more. Here’s what I can do for you:  \n",
            "\n",
            "### **What I Can Help With:**  \n",
            "✅ **Meeting Scheduling** – Find the best time for everyone, send invites, and manage calendars.  \n",
            "✅ **Agenda Creation** – Help draft and organize meeting topics to keep discussions focused.  \n",
            "✅ **Note-Taking & Summaries** – Capture key points, decisions, and action items during or after meetings.  \n",
            "✅ **Follow-Ups & Task Tracking** – Remind attendees of action items and deadlines post-meeting.  \n",
            "✅ **Transcription & Insights** – Summarize long discussions or extract important details from meeting transcripts.  \n",
            "✅ **Q&A & Clarifications** – Answer questions about past meetings or help prep for upcoming ones.  \n",
            "\n",
            "Need help with something specific? Just let me know! 😊\n"
          ]
        }
      ],
      "source": [
        "response = agent.run(\"Who are you and what can you do?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8OCLym00u28"
      },
      "source": [
        "Introduce what the agent is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I2sFFUVKjK7"
      },
      "source": [
        "## Prompt engineering\n",
        "\n",
        "Prompt engineering is important that can make your prompt more rich and useful for models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTTDeIAxKjNO"
      },
      "source": [
        "### Prompt usage\n",
        "\n",
        "Prompt can be used for interacting with models. The models understand your prompt and give responses.\n",
        "\n",
        "For example, with a prompt, a complex English statement can be optimized to be more concise:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1qrs9s10u28",
        "outputId": "e2679e02-549a-4546-ad75-ce56cb8ac306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1: I will give you a sentence, please make the sentence more concise and elegant.\n",
            "A1: Sure! Please provide the sentence, and I'll make it more concise and elegant.\n",
            "\n",
            "Q2: In a Chinese house, the kitchen is only a place for cooking things; but in many Western houses, the kitchen is not only a place where people cook meals and eat them but also a place where the family members or friends usually meet each other.\n",
            "A2: In Chinese homes, the kitchen serves solely for cooking. In contrast, in many Western households, it's not just for cooking and dining but also a gathering spot for family and friends. \n"
          ]
        }
      ],
      "source": [
        "from arkintelligence.model import ArkModel\n",
        "\n",
        "model = ArkModel(\n",
        "    model=\"doubao-1.5-pro-32k-250115\",\n",
        "    enbale_context=True,\n",
        ")\n",
        "\n",
        "prompt1 = \"I will give you a sentence, please make the sentence more concise and elegant.\"\n",
        "prompt2 = \"In a Chinese house, the kitchen is only a place for cooking things; but in many Western houses, the kitchen is not only a place where people cook meals and eat them but also a place where the family members or friends usually meet each other.\"\n",
        "\n",
        "res1 = model.chat(prompt1)\n",
        "res2 = model.chat(prompt2)\n",
        "\n",
        "print(f\"Q1: {prompt1}\")\n",
        "print(f\"A1: {res1}\\n\")\n",
        "\n",
        "print(f\"Q2: {prompt2}\")\n",
        "print(f\"A2: {res2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2nZWUb70u28"
      },
      "source": [
        "### Prompt refine\n",
        "\n",
        "Refine prompts is important, the comparision is as follows. We use a simple and a refined prompt to generate images, then compare the image quality.\n",
        "\n",
        "In fact, you can build an agent to refine prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_21pcLI0u28",
        "outputId": "e9ea7480-635d-435f-dd44-127c461c2d0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original prompt: Draw a cute golden british shorthair cat.\n",
            "\n",
            "Refined prompt: Create an adorable image of a Golden British Shorthair cat. The cat should have soft, lustrous golden - hued fur with a plush and velvety texture. Its round face should be adorned with large, bright, copper - colored eyes that exude a curious and innocent expression. The cat's ears are small, rounded at the tips, and sit neatly on its head. It has a short, stocky body with a plump belly, and its paws are dainty and well - proportioned. The background could be a cozy, sun - lit corner of a living room, perhaps with a soft, fluffy rug and a few scattered toys to enhance the cute and domesticated appeal.\n"
          ]
        }
      ],
      "source": [
        "from arkintelligence.agent import ArkAgent\n",
        "\n",
        "prompt = \"Draw a cute golden british shorthair cat.\"\n",
        "\n",
        "refine_agent = ArkAgent(\n",
        "    name=\"Prompt refine assistant\",\n",
        "    model=\"doubao-1-5-pro-256k-250115\",\n",
        "    prompt=\"Refine the prompt to make it more suitable for image generation.\",\n",
        ")\n",
        "prompt_refined = refine_agent.run(prompt)\n",
        "\n",
        "print(f\"Original prompt: {prompt}\\n\")\n",
        "print(f\"Refined prompt: {prompt_refined}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTogTxvV0u28"
      },
      "source": [
        "Then we use the two prompts to generate videos and see the differents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KORB226K0u28",
        "outputId": "66df5b99-f592-46ce-f2c8-355fb48d9bf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original video url is: https://ark-content-generation-cn-beijing.tos-cn-beijing.volces.com/doubao-seaweed/doubao-seaweed-2100390175-02174357522993500000000000000000000ffffac15606b87092c.mp4?X-Tos-Algorithm=TOS4-HMAC-SHA256&X-Tos-Credential=AKLTYjg3ZjNlOGM0YzQyNGE1MmI2MDFiOTM3Y2IwMTY3OTE%2F20250402%2Fcn-beijing%2Ftos%2Frequest&X-Tos-Date=20250402T062757Z&X-Tos-Expires=86400&X-Tos-Signature=ed38c5457d2a92b48c4ba79df28c4607efa94aeec1f82fb876a666723095a4e2&X-Tos-SignedHeaders=host\n",
            "Refined video url is: https://ark-content-generation-cn-beijing.tos-cn-beijing.volces.com/doubao-seaweed/doubao-seaweed-2100390175-02174357528376500000000000000000000ffffac15606b5a5252.mp4?X-Tos-Algorithm=TOS4-HMAC-SHA256&X-Tos-Credential=AKLTYjg3ZjNlOGM0YzQyNGE1MmI2MDFiOTM3Y2IwMTY3OTE%2F20250402%2Fcn-beijing%2Ftos%2Frequest&X-Tos-Date=20250402T062851Z&X-Tos-Expires=86400&X-Tos-Signature=92940cc3b3ae17a1b52864371249f699f716d95f3f28ede79255aa9f1853235c&X-Tos-SignedHeaders=host\n"
          ]
        }
      ],
      "source": [
        "from arkintelligence.model import ArkModel\n",
        "\n",
        "model = ArkModel(\n",
        "    model=\"doubao-seaweed-241128\",  # Use video generation model here\n",
        ")\n",
        "\n",
        "video = model.generate_video(\n",
        "    prompt=prompt,\n",
        ")\n",
        "video_with_refine = model.generate_video(\n",
        "    prompt=prompt_refined,\n",
        ")\n",
        "\n",
        "print(f'Original video url is: {video}' + '\\n')\n",
        "print(f'Refined video url is: {video_with_refine}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB6KcEvV0u28"
      },
      "source": [
        "### Equip to agent [WIP]\n",
        "\n",
        "You can enable prompt refine in your agent, the agent will **automatically refine your initial prompt** with a default refine prompt (you can modify this by pass `refine_prompt`). The usage is as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IZDBjdl0u28"
      },
      "outputs": [],
      "source": [
        "# TODO, WIP\n",
        "\n",
        "# from arkintelligence.agent import ArkAgent\n",
        "\n",
        "# prompt = \"Draw a cute golden british shorthair cat.\"\n",
        "\n",
        "# refine_agent = ArkAgent(\n",
        "#     name=\"Prompt refine assistant\",\n",
        "#     model=\"doubao-1-5-pro-256k-250115\",\n",
        "#     prompt=\"Refine the prompt to make it more suitable for image generation.\",\n",
        "#     refine_requirement=\"Refine the prompt to make it more suitable for image generation.\",\n",
        "# )\n",
        "# prompt_refined = refine_agent.run(prompt)\n",
        "\n",
        "# print(f\"Original prompt:\\n{prompt}\")\n",
        "# print(f\"Refined prompt:\\n{prompt_refined}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P1okD4n0u28"
      },
      "source": [
        "## Function calling\n",
        "\n",
        "The Ark agent can call your local function to finish your task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD0NiTO8L303"
      },
      "source": [
        "### Create a tool\n",
        "\n",
        "Before initializing an agent, you need to create a tool (which is just a Python function) to define tool logic. For example, we provide a `visit_url` here to read the website information:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBRiXznW0u28"
      },
      "outputs": [],
      "source": [
        "from arkintelligence.tool import ArkTool\n",
        "\n",
        "\n",
        "@ArkTool\n",
        "def visit_url(url: str):\n",
        "    \"\"\"Visit a URL and return the content.\n",
        "\n",
        "    This function can receive an url, and request to the url, then get the content of this url.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL to visit, generally begins with `http`.\n",
        "\n",
        "    Returns:\n",
        "        str: The content of the URL.\n",
        "    \"\"\"\n",
        "    response = \"This url introduces ArkIntelligence, including basic usage, agent building, and other advanced development methdology.\"\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7m7weHn0u28"
      },
      "source": [
        "Any function can be decorated by `ArkTool` to be a tool, which can be invoked by Ark agent.\n",
        "\n",
        "\n",
        "**NOTE:** The docstring of function is important, as its name, description and arguments will be sent to the model. The detailed docstring usage can be found [here]()."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hr7ZLxqMLqd"
      },
      "source": [
        "### Equip to agent\n",
        "\n",
        "You need to use the model which can support function calling.\n",
        "\n",
        "\n",
        "The created tool can be equipped to an agent with just only one option:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxAHNWEl0u28",
        "outputId": "b23f75df-5573-4125-ff4f-a397f1a28257"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The content of 'https://www.foo.bar.com/' introduces ArkIntelligence, including basic usage, agent building, and other advanced development methodology. \n"
          ]
        }
      ],
      "source": [
        "from arkintelligence.agent import ArkAgent\n",
        "\n",
        "agent = ArkAgent(\n",
        "    name=\"Web search assistant\",\n",
        "    model=\"doubao-1.5-pro-32k-250115\",\n",
        "    tools=[\"visit_url\"],\n",
        ")\n",
        "\n",
        "response = agent.run(\"What is the content of 'https://www.foo.bar.com/'?\")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoQF4T_tNt9z"
      },
      "source": [
        "In the output, the model can return our preset website content."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-ZC3WfA0u28"
      },
      "source": [
        "## RAG\n",
        "\n",
        "RAG enhances model response. In Ark, we provide concise method to enbale RAG.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Knowledge base\n",
        "\n",
        "Before creating knowledge base, we prepare `capitals.txt` file to save some knowledge items:"
      ],
      "metadata": {
        "id": "dMARGgV2X2ux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"capitals.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write('''\n",
        "    The capital of A is B;\n",
        "    The capital of B is C;\n",
        "    The capital of C is E;\n",
        "    The capital of of E is Z.\n",
        "    ''')"
      ],
      "metadata": {
        "id": "LhDssQI-fDmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can create the knowledge base with `capitals.txt` file like this:"
      ],
      "metadata": {
        "id": "WQgnKo60fD3W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATH0cDxq0u28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "fffb5b4208844f968ddfb1f205fae933",
            "f5685078476a47279d9b5b898ff33949",
            "5ab559225c764ca1b909f0746755fa8d",
            "61d02a7b2b0740ac8bcd47935aee467f",
            "cae074d0060b4d20a059f9195a5297b2",
            "4184d40bd22543e4a4e6b9f66a7d30bd",
            "836f1ca8b7d04bbbbd6d202f566c3fc8",
            "4639895f5ca24cbeace3a6e33dc28541",
            "1495ca68417a479ca573b3cf96dfc92c",
            "9c781e4a03e746858510e0e4060c1302",
            "64b0c7221b1642a5b8152107ec1e9014",
            "7dd5730e31814256aa80d48e05c0bd86",
            "50a11fbd095d4c4484786a00ed12ef8a",
            "d19771e91f80475ea39b824d9453efd0",
            "cd1624cf21b14eb99d06345962081a58",
            "204f00f0c5e440de82f00a7a9e270f9b",
            "02ac291f1ced4e5887153ed5f7c09432",
            "87e4511c889c42feae9a23e9b0ade69f",
            "9c61bf4d7fa44a349b08aa6592355052",
            "b394741e92fa410f9b509657e410bb75",
            "196e69269dcc4392b1b0a3ea799995a2",
            "3d5ab562691e40eaa487d421793db6da"
          ]
        },
        "outputId": "fcaa7be2-3669-4396-be8d-dc4d6d1b1b95"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fffb5b4208844f968ddfb1f205fae933"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7dd5730e31814256aa80d48e05c0bd86"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from arkintelligence.knowledgebase import ArkKnowledgeBase\n",
        "\n",
        "data = 'capitals.txt'\n",
        "\n",
        "kb = ArkKnowledgeBase(\n",
        "    name=\"ArkIntelligence\",\n",
        "    description=\"ArkIntelligence is a company that provides AI solutions.\",\n",
        "    data=data\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rXAIUjh0u28"
      },
      "source": [
        "During creation, your data will be uploaded to Ark platform and processed by embedding models such as `doubao-embed` (embed model API can be found [here]()). The processed data is stored in your local memory rather than cloud space.\n",
        "\n",
        "### Equip to agent\n",
        "\n",
        "Equip the knowledge base to your agent like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Afk8aV2O0u28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c7d487-37c4-4216-990d-f6070420d1f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on Reference No.1, the capital of E is Z. \n",
            "\n",
            "The reference provides a clear sequence of capitals:\n",
            "- The capital of A is B\n",
            "- The capital of B is C \n",
            "- The capital of C is E\n",
            "- The capital of E is Z\n",
            "\n",
            "The reference appears to be useful and relevant for answering this question, and the retrieval score of 0.82 indicates good confidence in the result. \n",
            "\n",
            "Final answer: The capital of E is Z.\n"
          ]
        }
      ],
      "source": [
        "agent = ArkAgent(\n",
        "    name=\"Knowledge base agent\",\n",
        "    model=\"deepseek-v3-250324\",\n",
        "    prompt=\"You are a helpful assistant.\",\n",
        "    knowldgebase=kb,\n",
        ")\n",
        "response = agent.run(\"What is the capital of E?\")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjGbBt6h0u29"
      },
      "source": [
        "# 📎 Awesome samples\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Customer service\n",
        "\n",
        "### Task description\n",
        "\n",
        "Reply to customer automatically.\n",
        "\n",
        "### Workflow\n",
        "\n",
        "1. ...\n",
        "2. ...\n",
        "\n",
        "### Capabilities\n",
        "\n",
        "1. RAG (Knowledge base)\n",
        "2. Prompt engineering\n",
        "\n",
        "### Models\n",
        "\n",
        "1. ...\n",
        "2. ...\n",
        "\n",
        "### Steps\n",
        "\n",
        "**Build knowledge base**\n",
        "\n",
        "**Promot refine**"
      ],
      "metadata": {
        "id": "2EPmK599mxXB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Information summarizer\n",
        "\n",
        "### Task description\n",
        "\n",
        "Give an url and summary template. The agent should visit the url, and summarize the url content according to the template file.\n",
        "\n",
        "### Workflow\n",
        "\n",
        "1. Visit URL, and get the content\n",
        "2. Summarize according to template file\n",
        "\n",
        "### Capabilities\n",
        "\n",
        "1. Function calling\n",
        "2. RAG (Knowledge base)\n",
        "\n",
        "### Models\n",
        "\n",
        "1. `doubao-1-5-pro-32k` for intention understanding\n",
        "2. `doubao-embedding-large` for knowledge base building\n",
        "\n",
        "### Steps\n",
        "\n",
        "**Build tool**\n",
        "\n",
        "In order to visit the given url, we need to program a tool for retriving website content:"
      ],
      "metadata": {
        "id": "Fgq80GzzxmyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from arkintelligence.tool import ArkTool\n",
        "\n",
        "from arkintelligence.tool import ArkTool\n",
        "\n",
        "\n",
        "@ArkTool\n",
        "def visit_url(url: str):\n",
        "    \"\"\"Visit a URL and return the content.\n",
        "\n",
        "    This function can receive an url, and request to the url, then get the content of this url.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL to visit, generally begins with `http`.\n",
        "\n",
        "    Returns:\n",
        "        str: The content of the URL.\n",
        "    \"\"\"\n",
        "    if url == \"https://pavm.example.com\":\n",
        "        content = \"\"\"\n",
        "        Paper title: PaVM: A Parallel Virtual Machine for Smart Contract Execution and Validation\n",
        "\n",
        "        Abstract: The performance bottleneck of blockchain has shifted from consensus to serial smart contract execution in transaction validation. Previous works predominantly focus on inter-contract parallel execution, but they fail to address the inherent limitations of each smart contract execution performance. In this paper, we propose PaVM, the first smart contract virtual machine that supports both inter-contract and intra-contract parallel execution to accelerate the validation process. PaVM consists of (1) key instructions for precisely recording entire runtime information at the instruction level, (2) a runtime system with a re-designed machine state and thread management to facilitate parallel execution, and (3) a read/write-operation-based receipt generation method to ensure both the correctness of operations and the consistency of blockchain data. We evaluate PaVM on the Ethereum testnet, demonstrating that it can outperform the mainstream blockchain client Geth. Our evaluation results reveal that PaVM speeds up overall validation performance by 33.4×, and enhances validation throughput by up to 46 times.\n",
        "        \"\"\"\n",
        "\n",
        "    return content"
      ],
      "metadata": {
        "id": "fqq6MXxlzGkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build knowledge base**\n",
        "\n",
        "In order to use the template file, we first create a `summary_template.md` to rule the summary template, then put this template file in knowledge base.\n",
        "\n",
        "First, we prepare the template file:"
      ],
      "metadata": {
        "id": "jeQW_rAvzQRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary_tamplate = '''\n",
        "# Insert paper title here\n",
        "\n",
        "This file is a template for scientific paper summary.\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Summary the paper's background and key technologies here.\n",
        "\n",
        "## Approach\n",
        "\n",
        "Summary the paper's primary work and contributions here.\n",
        "\n",
        "## Evaluation\n",
        "\n",
        "Summary the paper's primary evaluation results here.\n",
        "\n",
        "## Pros and Cons\n",
        "\n",
        "Summary the paper's pros and cons here.\n",
        "'''\n",
        "\n",
        "with open(\"paper_summary_template.md\", \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(summary_tamplate)"
      ],
      "metadata": {
        "id": "_cWmxVwgzqNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After that, we build the knowledge base according to the `summary_template.md`:"
      ],
      "metadata": {
        "id": "1mSzM9Apz-e9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from arkintelligence.agent import ArkAgent\n",
        "from arkintelligence.knowledgebase import ArkKnowledgeBase\n",
        "\n",
        "data = os.path.abspath(\"paper_summary_template.md\")\n",
        "knowledge_base = ArkKnowledgeBase(data=data)"
      ],
      "metadata": {
        "id": "rrUd-cn_0IFK",
        "outputId": "1b4726f0-2ad0-4799-a437-8735222bb013",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "95ca7610ae3d46d7956b0c51b947d300",
            "6261efb74571416db9dd4ab222cccba4",
            "6bba45fc7c934db1b805546993b381c4",
            "20c883c4d6124df4b3411fbcb2da5584",
            "69d004e3c7fc4bdbaf74f65e51e21db8",
            "c4b7756820ff41808c7f297787774bd5",
            "81e6acc794254e3d89642fab8263dcd6",
            "e479e43af8b847bd9dd85cb5762ab2bf",
            "e05e8cb640d44e8197574cc7014f04fe",
            "6ece55f8d6e9480b98cda5cb76a371b2",
            "6f794c2c9b804229b667e72a9af0399e",
            "5095def137af4369985cbbf9d50ed306",
            "fc9fea7e08754a9c8c7ff95cac6f3dd4",
            "69b85d30a1c64efd80ca5f54826bc034",
            "87e4a4a6930b403e98fe595283f2f796",
            "05a0d9cee6a346709e890d862d063728",
            "460b7d3772d04110bf1839abd51e9705",
            "ca9d82f49a5e4e54be6b27ec862899cd",
            "55033e86307741258581a753690ff5c9",
            "eb6fb477c9104ec1ab0e167ced314f9e",
            "f10aebfa8d894492885192c0f3f0d0e2",
            "245ca02b811e49258ee2b1ed14f7c8ec"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95ca7610ae3d46d7956b0c51b947d300"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5095def137af4369985cbbf9d50ed306"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build agent**\n",
        "\n",
        "We build the agent with the tool and knowledge base, and run this agent.\n",
        "\n",
        "We want the agent to retrieve the url content and summary the paper according to the template:"
      ],
      "metadata": {
        "id": "loojbRsF0pOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = ArkAgent(\n",
        "    name=\"Paper summarize agent\",\n",
        "    model=\"doubao-1.5-pro-32k-250115\", # Ensure the model can support function calling\n",
        "    prompt=\"You can visit url to get a paper, and summarize it.\",\n",
        "    tools=[\"visit_url\"],\n",
        "    knowldgebase=knowledge_base,\n",
        ")\n",
        "response = agent.run(\"Smmarize the PaVM according to paper summary template. The PaVM url is https://pavm.example.com\")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "WVlCKrY30ptG",
        "outputId": "428c4df8-4dc4-4f84-c6ad-164f01bc7047",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# PaVM: A Parallel Virtual Machine for Smart Contract Execution and Validation\n",
            "\n",
            "## Introduction\n",
            "The background of the paper is that the performance bottleneck of blockchain has shifted from consensus to serial smart - contract execution in transaction validation. Previous works mainly focused on inter - contract parallel execution and failed to deal with the inherent limitations of each smart contract's execution performance. The key technology here is PaVM, a new smart contract virtual machine aiming to accelerate the validation process.\n",
            "\n",
            "## Approach\n",
            "The primary work of the paper is to propose PaVM, the first smart contract virtual machine that supports both inter - contract and intra - contract parallel execution. Its contributions include:\n",
            "1. Designing key instructions to precisely record the entire runtime information at the instruction level.\n",
            "2. Developing a runtime system with a re - designed machine state and thread management to facilitate parallel execution.\n",
            "3. Presenting a read/write - operation - based receipt generation method to ensure the correctness of operations and the consistency of blockchain data.\n",
            "\n",
            "## Evaluation\n",
            "The paper evaluates PaVM on the Ethereum testnet. The primary evaluation results show that PaVM can outperform the mainstream blockchain client Geth. It speeds up the overall validation performance by 33.4× and enhances the validation throughput by up to 46 times.\n",
            "\n",
            "## Pros and Cons\n",
            "### Pros\n",
            "- PaVM addresses the existing problem of serial smart - contract execution in blockchain, which is the current performance bottleneck.\n",
            "- It supports both inter - contract and intra - contract parallel execution, which is a significant improvement compared to previous works.\n",
            "- The evaluation results on the Ethereum testnet are very promising, showing a large improvement in validation performance and throughput.\n",
            "### Cons\n",
            "There is no information provided in the given abstract about the cons of PaVM. Maybe potential drawbacks such as increased complexity in implementation, higher resource requirements, or compatibility issues are not mentioned here and could be explored in the full paper. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the above outputs, the model summarizes the paper content in the form of `paper_summary_template.md`. The agent finishs our task."
      ],
      "metadata": {
        "id": "9MkagJFm0gon"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recommendation engine\n",
        "\n",
        "### Task description\n",
        "\n",
        "Give a file that contains a list of user habits, the agent can recommends the other items to a specific user.\n",
        "\n",
        "### Workflow\n",
        "\n",
        "1. Get user habits from knowledge base\n",
        "2. Generate the similar items\n",
        "\n",
        "### Capabilities\n",
        "\n",
        "1. RAG (Knowledge base)\n",
        "\n",
        "### Models\n",
        "\n",
        "1. `doubao-1-5-pro-32k` for intention understanding\n",
        "2. `doubao-embedding-large` for knowledge base building\n",
        "\n",
        "### Steps\n",
        "\n",
        "**Build knowledge base**\n",
        "\n",
        "We build a knowledge base with a list of user habits:"
      ],
      "metadata": {
        "id": "QkLUAuWha1Du"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Platform monitor\n",
        "\n",
        "### Task description\n",
        "\n",
        "Give a image of network flow, the agent needs to recognize, analyze the problems and give solutions.\n",
        "\n",
        "### Workflow\n",
        "\n",
        "1. Understand the image\n",
        "2. Match problems\n",
        "\n",
        "### Capabilities\n",
        "\n",
        "1. Image understanding\n",
        "2. RAG (Knowledge base)\n",
        "\n",
        "### Models\n",
        "\n",
        "1. ...\n",
        "2. ...\n",
        "\n",
        "### Steps\n",
        "\n",
        "**Build knowledge base**\n",
        "\n",
        "**Image processing**"
      ],
      "metadata": {
        "id": "PhA1dTbLnHkN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🤗 Development\n",
        "---"
      ],
      "metadata": {
        "id": "mRbLB3r4XE_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logging\n",
        "\n",
        "**NOTE:** This feature is experimental, has bugs.\n",
        "\n",
        "By default, the logging is disabled to make the output clear.\n"
      ],
      "metadata": {
        "id": "RsQHa0ZpXHzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from arkintelligence.utils.logger import logger\n",
        "\n",
        "# By default, the logging is disabled,\n",
        "# you will see nothing but the final output of the agent\n",
        "print('Logging is disabled by default.\\n')\n",
        "\n",
        "from arkintelligence.agent import ArkAgent\n",
        "\n",
        "agent = ArkAgent(\n",
        "    name=\"Agent\",\n",
        "    model=\"deepseek-v3-250324\",\n",
        ")\n",
        "\n",
        "response = agent.run('Hello!')\n",
        "print(response)"
      ],
      "metadata": {
        "id": "JEmKkZl9Lmto",
        "outputId": "e9b5bd0b-36ae-4079-9663-3ea4e5f5fa30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging is disabled by default.\n",
            "\n",
            "Hello! 👋 How can I assist you today? Whether it's answering questions, solving problems, or just having a chat, I'm here to help! Let me know what you need. 😊\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can enable logging by executing `logger.enable` before running your application:"
      ],
      "metadata": {
        "id": "RE_GiRMLL1dL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from arkintelligence.utils.logger import logger\n",
        "\n",
        "# Enable logging by `logger.enable()`\n",
        "# you will see logs and the final output\n",
        "logger.enable('arkintelligence')\n",
        "print('Logging is enabled.\\n')\n",
        "\n",
        "agent = ArkAgent(\n",
        "    name=\"Agent\",\n",
        "    model=\"deepseek-v3-250324\",\n",
        ")\n",
        "\n",
        "response = agent.run('Hello!')\n",
        "print(response)"
      ],
      "metadata": {
        "id": "KBifyV6YXRzL",
        "outputId": "646daed0-8490-4c2f-fc75-8af3abb05e86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-04-03 01:11:14\u001b[0m | \u001b[36mINFO    \u001b[0m | \u001b[32mArkAgent.py\u001b[0m:\u001b[32m24\u001b[0m - \u001b[36mInitializing [Agent] agent with model [deepseek-v3-250324]\u001b[0m\n",
            "\u001b[32m2025-04-03 01:11:14\u001b[0m | \u001b[36mINFO    \u001b[0m | \u001b[32mArkModel.py\u001b[0m:\u001b[32m18\u001b[0m - \u001b[36mInitializing model [deepseek-v3-250324]\u001b[0m\n",
            "\u001b[32m2025-04-03 01:11:14\u001b[0m | \u001b[37mDEBUG   \u001b[0m | \u001b[32mArkAgent.py\u001b[0m:\u001b[32m54\u001b[0m - \u001b[37muser: Hello!\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging is enabled.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-04-03 01:11:17\u001b[0m | \u001b[37mDEBUG   \u001b[0m | \u001b[32mArkAgent.py\u001b[0m:\u001b[32m64\u001b[0m - \u001b[37massistant: ChatCompletion(id='0217436426753228084878a591734e67baeafda3dc9c22733148a', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Hello there! 👋 How can I assist you today? Whether you have questions, need help with a task, or just want to chat, I'm here to help! Let me know what's on your mind. 😊\", refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1743642677, model='deepseek-v3-250324', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=46, prompt_tokens=22, total_tokens=68, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))\u001b[0m\n",
            "\u001b[32m2025-04-03 01:11:17\u001b[0m | \u001b[37mDEBUG   \u001b[0m | \u001b[32mArkAgent.py\u001b[0m:\u001b[32m120\u001b[0m - \u001b[37mFinal response: Hello there! 👋 How can I assist you today? Whether you have questions, need help with a task, or just want to chat, I'm here to help! Let me know what's on your mind. 😊\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello there! 👋 How can I assist you today? Whether you have questions, need help with a task, or just want to chat, I'm here to help! Let me know what's on your mind. 😊\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logging can be disabled by `logger.disable()`."
      ],
      "metadata": {
        "id": "GsdbFmF6MFj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from arkintelligence.utils.logger import logger\n",
        "\n",
        "# Disable logging by `logger.disable()`\n",
        "print('Logging is disabled.\\n')\n",
        "\n",
        "logger.disable('arkintelligence')\n",
        "\n",
        "agent = ArkAgent(\n",
        "    name=\"Agent\",\n",
        "    model=\"deepseek-v3-250324\",\n",
        ")\n",
        "\n",
        "response = agent.run('Hello!')\n",
        "print(response)"
      ],
      "metadata": {
        "id": "5hmD5EmXL8-N",
        "outputId": "5d513b1c-123b-4a17-9a14-250df3e94d7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging is disabled.\n",
            "\n",
            "Hello! 👋 How can I assist you today? Whether you have questions, need help with a task, or just want to chat, I'm here to help! Let me know what you're looking for. 😊\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tracing"
      ],
      "metadata": {
        "id": "MESSlYI0NKJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain-of-Thoughts\n"
      ],
      "metadata": {
        "id": "Pc1Lf6PKNC4-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Benchmark"
      ],
      "metadata": {
        "id": "9rEv612fNO2M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Micro benchmark"
      ],
      "metadata": {
        "id": "WipBlBVpNW9j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Macro benchmark"
      ],
      "metadata": {
        "id": "13QVLHr2NZvh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contribution\n",
        "\n",
        "Welcome contribute to us!"
      ],
      "metadata": {
        "id": "sySwDbMzXYmB"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "arkintelligence",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fffb5b4208844f968ddfb1f205fae933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5685078476a47279d9b5b898ff33949",
              "IPY_MODEL_5ab559225c764ca1b909f0746755fa8d",
              "IPY_MODEL_61d02a7b2b0740ac8bcd47935aee467f"
            ],
            "layout": "IPY_MODEL_cae074d0060b4d20a059f9195a5297b2"
          }
        },
        "f5685078476a47279d9b5b898ff33949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4184d40bd22543e4a4e6b9f66a7d30bd",
            "placeholder": "​",
            "style": "IPY_MODEL_836f1ca8b7d04bbbbd6d202f566c3fc8",
            "value": "Parsing nodes: 100%"
          }
        },
        "5ab559225c764ca1b909f0746755fa8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4639895f5ca24cbeace3a6e33dc28541",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1495ca68417a479ca573b3cf96dfc92c",
            "value": 1
          }
        },
        "61d02a7b2b0740ac8bcd47935aee467f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c781e4a03e746858510e0e4060c1302",
            "placeholder": "​",
            "style": "IPY_MODEL_64b0c7221b1642a5b8152107ec1e9014",
            "value": " 1/1 [00:00&lt;00:00, 50.12it/s]"
          }
        },
        "cae074d0060b4d20a059f9195a5297b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4184d40bd22543e4a4e6b9f66a7d30bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "836f1ca8b7d04bbbbd6d202f566c3fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4639895f5ca24cbeace3a6e33dc28541": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1495ca68417a479ca573b3cf96dfc92c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c781e4a03e746858510e0e4060c1302": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64b0c7221b1642a5b8152107ec1e9014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dd5730e31814256aa80d48e05c0bd86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50a11fbd095d4c4484786a00ed12ef8a",
              "IPY_MODEL_d19771e91f80475ea39b824d9453efd0",
              "IPY_MODEL_cd1624cf21b14eb99d06345962081a58"
            ],
            "layout": "IPY_MODEL_204f00f0c5e440de82f00a7a9e270f9b"
          }
        },
        "50a11fbd095d4c4484786a00ed12ef8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02ac291f1ced4e5887153ed5f7c09432",
            "placeholder": "​",
            "style": "IPY_MODEL_87e4511c889c42feae9a23e9b0ade69f",
            "value": "Generating embeddings: 100%"
          }
        },
        "d19771e91f80475ea39b824d9453efd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c61bf4d7fa44a349b08aa6592355052",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b394741e92fa410f9b509657e410bb75",
            "value": 1
          }
        },
        "cd1624cf21b14eb99d06345962081a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_196e69269dcc4392b1b0a3ea799995a2",
            "placeholder": "​",
            "style": "IPY_MODEL_3d5ab562691e40eaa487d421793db6da",
            "value": " 1/1 [00:00&lt;00:00,  1.30it/s]"
          }
        },
        "204f00f0c5e440de82f00a7a9e270f9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02ac291f1ced4e5887153ed5f7c09432": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87e4511c889c42feae9a23e9b0ade69f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c61bf4d7fa44a349b08aa6592355052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b394741e92fa410f9b509657e410bb75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "196e69269dcc4392b1b0a3ea799995a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d5ab562691e40eaa487d421793db6da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95ca7610ae3d46d7956b0c51b947d300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6261efb74571416db9dd4ab222cccba4",
              "IPY_MODEL_6bba45fc7c934db1b805546993b381c4",
              "IPY_MODEL_20c883c4d6124df4b3411fbcb2da5584"
            ],
            "layout": "IPY_MODEL_69d004e3c7fc4bdbaf74f65e51e21db8"
          }
        },
        "6261efb74571416db9dd4ab222cccba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4b7756820ff41808c7f297787774bd5",
            "placeholder": "​",
            "style": "IPY_MODEL_81e6acc794254e3d89642fab8263dcd6",
            "value": "Parsing nodes: 100%"
          }
        },
        "6bba45fc7c934db1b805546993b381c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e479e43af8b847bd9dd85cb5762ab2bf",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e05e8cb640d44e8197574cc7014f04fe",
            "value": 1
          }
        },
        "20c883c4d6124df4b3411fbcb2da5584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ece55f8d6e9480b98cda5cb76a371b2",
            "placeholder": "​",
            "style": "IPY_MODEL_6f794c2c9b804229b667e72a9af0399e",
            "value": " 1/1 [00:00&lt;00:00, 35.13it/s]"
          }
        },
        "69d004e3c7fc4bdbaf74f65e51e21db8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4b7756820ff41808c7f297787774bd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81e6acc794254e3d89642fab8263dcd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e479e43af8b847bd9dd85cb5762ab2bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e05e8cb640d44e8197574cc7014f04fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ece55f8d6e9480b98cda5cb76a371b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f794c2c9b804229b667e72a9af0399e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5095def137af4369985cbbf9d50ed306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc9fea7e08754a9c8c7ff95cac6f3dd4",
              "IPY_MODEL_69b85d30a1c64efd80ca5f54826bc034",
              "IPY_MODEL_87e4a4a6930b403e98fe595283f2f796"
            ],
            "layout": "IPY_MODEL_05a0d9cee6a346709e890d862d063728"
          }
        },
        "fc9fea7e08754a9c8c7ff95cac6f3dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_460b7d3772d04110bf1839abd51e9705",
            "placeholder": "​",
            "style": "IPY_MODEL_ca9d82f49a5e4e54be6b27ec862899cd",
            "value": "Generating embeddings: 100%"
          }
        },
        "69b85d30a1c64efd80ca5f54826bc034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55033e86307741258581a753690ff5c9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb6fb477c9104ec1ab0e167ced314f9e",
            "value": 1
          }
        },
        "87e4a4a6930b403e98fe595283f2f796": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f10aebfa8d894492885192c0f3f0d0e2",
            "placeholder": "​",
            "style": "IPY_MODEL_245ca02b811e49258ee2b1ed14f7c8ec",
            "value": " 1/1 [00:01&lt;00:00,  1.25s/it]"
          }
        },
        "05a0d9cee6a346709e890d862d063728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "460b7d3772d04110bf1839abd51e9705": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca9d82f49a5e4e54be6b27ec862899cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55033e86307741258581a753690ff5c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb6fb477c9104ec1ab0e167ced314f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f10aebfa8d894492885192c0f3f0d0e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "245ca02b811e49258ee2b1ed14f7c8ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}