{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "A freshman-friendly tutorial for Ark platform.\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Why Ark?\n",
    "\n",
    "Ark is a platform that supports multiple kinds of models running.\n",
    "\n",
    "### Productions\n",
    "\n",
    "Productions in ARK, including models, agents and something else.\n",
    "\n",
    "### Rodemap\n",
    "\n",
    "Rodemap and primary changelog of Ark.\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Installation\n",
    "\n",
    "Install Ark SDK from Github repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting git+https://githubfast.com/LotsoTeddy/ArkIntelligence.git\n",
      "  Cloning https://githubfast.com/LotsoTeddy/ArkIntelligence.git to /tmp/pip-req-build-qdh3b43i\n",
      "  Running command git clone --filter=blob:none --quiet https://githubfast.com/LotsoTeddy/ArkIntelligence.git /tmp/pip-req-build-qdh3b43i\n",
      "  Resolved https://githubfast.com/LotsoTeddy/ArkIntelligence.git to commit 195d3a85d877b45ebaaaab6c705fecbc989c3c53\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from ArkIntelligence==1.0.0) (2.32.3)\n",
      "Requirement already satisfied: openai>=1.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from ArkIntelligence==1.0.0) (1.70.0)\n",
      "Requirement already satisfied: docstring_parser in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from ArkIntelligence==1.0.0) (0.16)\n",
      "Requirement already satisfied: volcengine in /root/.local/lib/python3.10/site-packages (from ArkIntelligence==1.0.0) (1.0.177)\n",
      "Requirement already satisfied: llama-index in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from ArkIntelligence==1.0.0) (0.12.27)\n",
      "Requirement already satisfied: loguru in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from ArkIntelligence==1.0.0) (0.7.3)\n",
      "Requirement already satisfied: volcengine-python-sdk[ark] in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from ArkIntelligence==1.0.0) (1.1.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from openai>=1.0->ArkIntelligence==1.0.0) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from openai>=1.0->ArkIntelligence==1.0.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from openai>=1.0->ArkIntelligence==1.0.0) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from openai>=1.0->ArkIntelligence==1.0.0) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from openai>=1.0->ArkIntelligence==1.0.0) (2.11.1)\n",
      "Requirement already satisfied: sniffio in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from openai>=1.0->ArkIntelligence==1.0.0) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from openai>=1.0->ArkIntelligence==1.0.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from openai>=1.0->ArkIntelligence==1.0.0) (4.13.0)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index->ArkIntelligence==1.0.0) (0.4.6)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.1 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index->ArkIntelligence==1.0.0) (0.4.1)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.27 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index->ArkIntelligence==1.0.0) (0.12.27)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index->ArkIntelligence==1.0.0) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index->ArkIntelligence==1.0.0) (0.6.10)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index->ArkIntelligence==1.0.0) (0.3.29)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index->ArkIntelligence==1.0.0) (0.4.3)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index->ArkIntelligence==1.0.0) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index->ArkIntelligence==1.0.0) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index->ArkIntelligence==1.0.0) (0.4.7)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index->ArkIntelligence==1.0.0) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index->ArkIntelligence==1.0.0) (3.9.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from requests->ArkIntelligence==1.0.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from requests->ArkIntelligence==1.0.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from requests->ArkIntelligence==1.0.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from requests->ArkIntelligence==1.0.0) (2025.1.31)\n",
      "Requirement already satisfied: retry==0.9.2 in /root/.local/lib/python3.10/site-packages (from volcengine->ArkIntelligence==1.0.0) (0.9.2)\n",
      "Requirement already satisfied: pytz==2020.5 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from volcengine->ArkIntelligence==1.0.0) (2020.5)\n",
      "Requirement already satisfied: pycryptodome==3.9.9 in /root/.local/lib/python3.10/site-packages (from volcengine->ArkIntelligence==1.0.0) (3.9.9)\n",
      "Requirement already satisfied: protobuf>=3.18.3 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from volcengine->ArkIntelligence==1.0.0) (6.30.2)\n",
      "Requirement already satisfied: google>=3.0.0 in /root/.local/lib/python3.10/site-packages (from volcengine->ArkIntelligence==1.0.0) (3.0.0)\n",
      "Requirement already satisfied: six>=1.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from volcengine->ArkIntelligence==1.0.0) (1.17.0)\n",
      "Requirement already satisfied: decorator>=3.4.2 in /root/.local/lib/python3.10/site-packages (from retry==0.9.2->volcengine->ArkIntelligence==1.0.0) (5.2.1)\n",
      "Requirement already satisfied: py<2.0.0,>=1.4.26 in /root/.local/lib/python3.10/site-packages (from retry==0.9.2->volcengine->ArkIntelligence==1.0.0) (1.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from volcengine-python-sdk[ark]->ArkIntelligence==1.0.0) (2.9.0.post0)\n",
      "Requirement already satisfied: cryptography<43.0.4,>=43.0.3 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from volcengine-python-sdk[ark]->ArkIntelligence==1.0.0) (43.0.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.0->ArkIntelligence==1.0.0) (1.2.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from cryptography<43.0.4,>=43.0.3->volcengine-python-sdk[ark]->ArkIntelligence==1.0.0) (1.17.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /root/.local/lib/python3.10/site-packages (from google>=3.0.0->volcengine->ArkIntelligence==1.0.0) (4.13.3)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.0->ArkIntelligence==1.0.0) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0->ArkIntelligence==1.0.0) (0.14.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (2.0.40)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (3.11.15)\n",
      "Requirement already satisfied: banks<3.0.0,>=2.0.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (2.1.1)\n",
      "Requirement already satisfied: dataclasses-json in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (2025.3.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (3.4.2)\n",
      "Requirement already satisfied: numpy in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (2.2.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (11.1.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (0.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (1.17.2)\n",
      "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.13 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->ArkIntelligence==1.0.0) (0.1.17)\n",
      "Requirement already satisfied: pandas in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->ArkIntelligence==1.0.0) (2.2.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->ArkIntelligence==1.0.0) (5.4.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->ArkIntelligence==1.0.0) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index->ArkIntelligence==1.0.0) (0.6.4.post1)\n",
      "Requirement already satisfied: click in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from nltk>3.8.1->llama-index->ArkIntelligence==1.0.0) (8.1.8)\n",
      "Requirement already satisfied: joblib in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from nltk>3.8.1->llama-index->ArkIntelligence==1.0.0) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from nltk>3.8.1->llama-index->ArkIntelligence==1.0.0) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.0->ArkIntelligence==1.0.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.0->ArkIntelligence==1.0.0) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.0->ArkIntelligence==1.0.0) (0.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (6.3.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (1.18.3)\n",
      "Requirement already satisfied: griffe in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (1.7.1)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (4.3.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in /root/.local/lib/python3.10/site-packages (from beautifulsoup4->google>=3.0.0->volcengine->ArkIntelligence==1.0.0) (2.6)\n",
      "Requirement already satisfied: pycparser in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from cffi>=1.12->cryptography<43.0.4,>=43.0.3->volcengine-python-sdk[ark]->ArkIntelligence==1.0.0) (2.22)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.4 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ArkIntelligence==1.0.0) (0.6.9)\n",
      "Requirement already satisfied: greenlet>=1 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (3.26.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->ArkIntelligence==1.0.0) (2025.2)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from llama-cloud-services>=0.6.4->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ArkIntelligence==1.0.0) (1.1.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (24.2)\n",
      "Requirement already satisfied: colorama>=0.4 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from griffe->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/arkintelligence/lib/python3.10/site-packages (from jinja2->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.27->llama-index->ArkIntelligence==1.0.0) (3.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install git+https://githubfast.com/LotsoTeddy/ArkIntelligence.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication\n",
    "\n",
    "Go to https://www.example.com to generate your API key, and set it in your code or environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"ARK_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart\n",
    "\n",
    "You can chat with a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIConnectionError",
     "evalue": "Connection error.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLocalProtocolError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/httpx/_transports/default.py:101\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/httpcore/_sync/http11.py:86\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msend_request_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     85\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msend_request_body\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/httpcore/_sync/http11.py:144\u001b[0m, in \u001b[0;36mHTTP11Connection._send_request_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    142\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions({h11\u001b[38;5;241m.\u001b[39mLocalProtocolError: LocalProtocolError}):\n\u001b[1;32m    145\u001b[0m     event \u001b[38;5;241m=\u001b[39m h11\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    146\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    147\u001b[0m         target\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39murl\u001b[38;5;241m.\u001b[39mtarget,\n\u001b[1;32m    148\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    149\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/httpcore/_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mLocalProtocolError\u001b[0m: Illegal header value b'Bearer '",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mLocalProtocolError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/openai/_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 955\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/httpx/_transports/default.py:249\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[0;32m--> 249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m    250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/httpx/_transports/default.py:118\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mLocalProtocolError\u001b[0m: Illegal header value b'Bearer '",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01markintelligence\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArkModel\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m ArkModel(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoubao-1.5-pro-32k-250115\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWho are you?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m response\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/arkintelligence/model/ArkModel.py:59\u001b[0m, in \u001b[0;36mArkModel.chat\u001b[0;34m(self, prompt, attachment)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}]\n\u001b[0;32m---> 59\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mpost_to_text_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_context:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_mgr\u001b[38;5;241m.\u001b[39madd_to_context(\n\u001b[1;32m     66\u001b[0m         role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, content\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     67\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/arkintelligence/base/checker.py:13\u001b[0m, in \u001b[0;36mapi_key_check.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     12\u001b[0m     _api_key_check()\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/arkintelligence/base/apis.py:24\u001b[0m, in \u001b[0;36mpost_to_text_model\u001b[0;34m(model, messages, tools)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;129m@api_key_check\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost_to_text_model\u001b[39m(\n\u001b[1;32m     16\u001b[0m     model: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     17\u001b[0m     messages: List[\u001b[38;5;28mdict\u001b[39m],\n\u001b[1;32m     18\u001b[0m     tools: List \u001b[38;5;241m=\u001b[39m [],\n\u001b[1;32m     19\u001b[0m ):\n\u001b[1;32m     20\u001b[0m     client \u001b[38;5;241m=\u001b[39m OpenAI(\n\u001b[1;32m     21\u001b[0m         base_url\u001b[38;5;241m=\u001b[39mMODEL_URL_MAPPING[model],\n\u001b[1;32m     22\u001b[0m         api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mARK_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     23\u001b[0m     )\n\u001b[0;32m---> 24\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:914\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    911\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    912\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    913\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/openai/_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1241\u001b[0m     )\n\u001b[0;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/openai/_base_client.py:919\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 919\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/openai/_base_client.py:979\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    976\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered Exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 979\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/openai/_base_client.py:1057\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/openai/_base_client.py:979\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    976\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered Exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 979\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/openai/_base_client.py:1057\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/arkintelligence/lib/python3.10/site-packages/openai/_base_client.py:989\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[1;32m    980\u001b[0m             input_options,\n\u001b[1;32m    981\u001b[0m             cast_to,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    985\u001b[0m             response_headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m         )\n\u001b[1;32m    988\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    991\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    992\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP Response: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    993\u001b[0m     request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    997\u001b[0m     response\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    998\u001b[0m )\n\u001b[1;32m    999\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest_id: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx-request-id\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m: Connection error."
     ]
    }
   ],
   "source": [
    "from arkintelligence.model import ArkModel\n",
    "\n",
    "model = ArkModel(model=\"doubao-1.5-pro-32k-250115\")\n",
    "\n",
    "response = model.chat(prompt=\"Who are you?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you can create a Translator agent to translate your text from English to Chinese:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from arkintelligence.agent import ArkAgent\n",
    "\n",
    "agent = ArkAgent(\n",
    "    name=\"Translator\",\n",
    "    model=\"doubao-1.5-pro-32k-250115\",\n",
    "    prompt=\"Translate the input text from English to Chinese.\",\n",
    ")\n",
    "\n",
    "res = agent.run(\"Inspire Creativity, Enrich Life!\")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic usage\n",
    "\n",
    "## Overview\n",
    "\n",
    "The entire list of model ID can be found [here](). The capabilities of each model is listed as follows:\n",
    "\n",
    "| Model ID      | Image understanding | Video generation | Function calling | \n",
    "| - | - | - | - |\n",
    "| doubao-1.5-vision-pro-32k-250115 |  | | |\n",
    "| doubao-seaweed-241128 | |  | |\n",
    "\n",
    "## Text capabilities\n",
    "\n",
    "### Chat\n",
    "\n",
    "Single-turn completion has no memory, so the previous user chat will not stored during chat. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got it! My name is ArkIntelligence. From now on, you can call me by this name whenever you interact with me. \n",
      "My name is Doubao. Nice to meet you!\n"
     ]
    }
   ],
   "source": [
    "from arkintelligence.model import ArkModel\n",
    "\n",
    "model = ArkModel(model=\"doubao-1.5-pro-32k-250115\")\n",
    "\n",
    "response = model.chat(prompt=\"Your name is ArkIntelligence.\")\n",
    "print(response + '\\n')\n",
    "\n",
    "response = model.chat(prompt=\"What is your name?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat with memory\n",
    "\n",
    "Multi-turn chat has memory, the model can remember the history messages by setting `enable_context=True` during initialization. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for naming me ArkIntelligence. From now on, I'll answer your questions and have conversations with you under this name. If you have any queries, just tell me! \n",
      "My name is ArkIntelligence. I'm here to assist you with any questions you might have. \n"
     ]
    }
   ],
   "source": [
    "from arkintelligence.model import ArkModel\n",
    "\n",
    "model = ArkModel(\n",
    "    model=\"doubao-1.5-pro-32k-250115\",\n",
    "    enbale_context=True # Make LLM remember the context\n",
    "    )\n",
    "\n",
    "response = model.chat(prompt=\"Your name is ArkIntelligence.\")\n",
    "print(response + '\\n')\n",
    "\n",
    "response = model.chat(prompt=\"What is your name?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can remember the previous user input.\n",
    "\n",
    "### Chat with attachment\n",
    "\n",
    "We support upload your single file with format of `.txt`, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkintelligence.model import ArkModel\n",
    "\n",
    "model = ArkModel(model=\"doubao-1.5-pro-32k-250115\")\n",
    "\n",
    "response = model.chat(\n",
    "    prompt=\"Your name is ArkIntelligence.\",\n",
    "    attachment=\"FILE_PATH\",  # TODO(LotsoTeddy): Parsing attachment\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision capabilities\n",
    "\n",
    "Ark provides capabilities about multi-media, such as vision and sounds. Here we introduce the vision-related demos.\n",
    "\n",
    "### Image understanding\n",
    "\n",
    "We use LLM to understand the following image:\n",
    "\n",
    "<img src='https://ark-tutorial.tos-cn-beijing.volces.com/assets/images/cat.png' style='width:150px'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This is a close - up photograph of an adorable cat. The cat has a soft, plush coat in a light grayish - beige color. Its fur appears very well - groomed and smooth. The cat's most striking feature is its large, round eyes that are a dark, almost black color, giving it an expression of wide - eyed curiosity or surprise. Its ears are upright and have a light pink interior, adding a touch of contrast to its overall appearance.\\n\\nThe cat's nose is a small, delicate pink, and its whiskers are long, white, and prominent, extending outward from its cheeks. It is lying down on a light - colored surface, possibly a carpet or a mat, with its front paws stretched out in front of it.\\n\\nIn the background, the setting seems to be indoors. There are some indistinct objects, including what looks like part of a piece of furniture, perhaps a chair or a cabinet, and some other household items that are out of focus, ensuring that the cat remains the central subject of the image. The overall atmosphere of the picture is warm and cozy, highlighting the cat's cute and endearing qualities. \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from arkintelligence.model import ArkModel\n",
    "\n",
    "IMAGE_PATH = \"./assets/images/cat.png\"\n",
    "model = ArkModel(\n",
    "    model=\"doubao-1.5-vision-pro-32k-250115\",  # Use vision model here\n",
    ")\n",
    "\n",
    "response = model.process_image(\n",
    "    prompt=\"Please describe this image with details.\",\n",
    "    attachment=IMAGE_PATH,\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video generation\n",
    "\n",
    "We use `doubao` model to generate a video according to a static image and prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REF_IMAGE_PATH = \"./assets/images/cat.png\"\n",
    "model = ArkModel(\n",
    "    model=\"doubao-seaweed-241128\",  # Use video generation model here\n",
    ")\n",
    "\n",
    "response = model.generate_video(\n",
    "    prompt=\"Please generate a video with a cat running.\",\n",
    "    attachment=REF_IMAGE_PATH,\n",
    ") # This will take a while\n",
    "\n",
    "print(\"Waiting for video generation...\")\n",
    "print(\"Generated video url is: \" + response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> Want to make the video more vivid? Maybe you need: prompt refine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent\n",
    "\n",
    "## A minimal agent\n",
    "\n",
    "A simple agent can be built with several lines. The `name` field is not necessary, but provide it will make agent more intelligent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkintelligence.agent import ArkAgent\n",
    "\n",
    "agent = ArkAgent(\n",
    "    name=\"Meeting assistant\",\n",
    "    model=\"deepseek-v3-250324\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can chat with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm your **Meeting Assistant**, here to help you with anything related to meetingswhether it's scheduling, note-taking, summarizing discussions, setting agendas, or following up on action items.  \\n\\nHow can I assist you today? \""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent.run(\"Who are you?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A complex agent with several capabilities (such as knowledge base and function calling) just needs more 2 lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduce what the agent is.\n",
    "\n",
    "## Prompt engineering\n",
    "\n",
    "Prompt engineering is important that can make your prompt more rich and useful for models.\n",
    "\n",
    "### Prompt usage\n",
    "\n",
    "Prompt can be used for interacting with models. The models understand your prompt and give responses. For example, with a prompt, a complex English statement can be optimized to be more concise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Please provide the sentence, and I'll do my best to make it more concise and elegant.\n",
      "In Chinese houses, the kitchen serves solely for cooking. However, in many Western homes, it's not just a cooking and dining area but also a gathering place for family and friends. \n"
     ]
    }
   ],
   "source": [
    "from arkintelligence.model import ArkModel\n",
    "\n",
    "model = ArkModel(\n",
    "    model=\"doubao-1.5-pro-32k-250115\",\n",
    "    enbale_context=True,\n",
    ")\n",
    "\n",
    "response = model.chat(\n",
    "    prompt=\"I will give you a sentence, please make the sentence more concise and elegant.\"\n",
    ")\n",
    "print(response + '\\n')\n",
    "\n",
    "response = model.chat(\n",
    "    prompt=\"In a Chinese house, the kitchen is only a place for cooking things; but in many Western houses, the kitchen is not only a place where people cook meals and eat them but also a place where the family members or friends usually meet each other.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt refine\n",
    "\n",
    "Refine prompts is important, the comparision is as follows. We use a simple and a refined prompt to generate images, then compare the image quality.\n",
    "\n",
    "You can build an agent to refine prompt: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prompt:\n",
      "Draw a cute golden british shorthair cat.\n",
      "Refined prompt:\n",
      "Create an image of an adorable Golden British Shorthair cat. Focus on the cat's round face, big, bright eyes, short and plush fur with a warm golden hue. Include details like the cat's small, rounded ears, a slightly chubby body, and its soft paws. The cat could be in a relaxed pose, perhaps sitting or lying down, with an expression that exudes cuteness and charm. Consider adding a simple, cozy background like a soft blanket or a sunny corner of a room to enhance the overall appealing and endearing atmosphere. \n"
     ]
    }
   ],
   "source": [
    "from arkintelligence.agent import ArkAgent\n",
    "\n",
    "prompt = \"Draw a cute golden british shorthair cat.\"\n",
    "\n",
    "refine_agent = ArkAgent(\n",
    "    name=\"Prompt refine assistant\",\n",
    "    model=\"doubao-1-5-pro-256k-250115\",\n",
    "    prompt=\"Refine the prompt to make it more suitable for image generation.\",\n",
    ")\n",
    "prompt_refined = refine_agent.run(prompt)\n",
    "\n",
    "print(f\"Original prompt:\\n{prompt}\")\n",
    "print(f\"Refined prompt:\\n{prompt_refined}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the two prompts to generate videos and see the differents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkintelligence.model import ArkModel\n",
    "\n",
    "model = ArkModel(\n",
    "    model=\"doubao-seaweed-241128\",  # Use video generation model here\n",
    ")\n",
    "\n",
    "video = model.generate_video(\n",
    "    prompt=prompt,\n",
    ")\n",
    "video_with_refine = model.generate_video(\n",
    "    prompt=prompt_refined,\n",
    ")\n",
    "\n",
    "print(f'Original video url is: {video}')\n",
    "print(f'Refined video url is: {video_with_refine}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equip to agent\n",
    "\n",
    "You can enable prompt refine in your agent, the agent will automatically refine your **first** prompt with a default refine prompt (you can modify this by pass `refine_prompt`). The usage is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkintelligence.agent import ArkAgent\n",
    "\n",
    "prompt = \"Draw a cute golden british shorthair cat.\"\n",
    "\n",
    "refine_agent = ArkAgent(\n",
    "    name=\"Prompt refine assistant\",\n",
    "    model=\"doubao-1-5-pro-256k-250115\",\n",
    "    prompt=\"Refine the prompt to make it more suitable for image generation.\",\n",
    "    refine_requirement=\"Refine the prompt to make it more suitable for image generation.\",\n",
    ")\n",
    "prompt_refined = refine_agent.run(prompt)\n",
    "\n",
    "print(f\"Original prompt:\\n{prompt}\")\n",
    "print(f\"Refined prompt:\\n{prompt_refined}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function calling\n",
    "\n",
    "The Ark agent can call your local function to finish your task.\n",
    "\n",
    "### Tool\n",
    "\n",
    "Before init an agent, you should create a tool (which is a Python function) to define tool logic. For example, we provide a `visit_url` here to read the website information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkintelligence.tool import ArkTool\n",
    "\n",
    "@ArkTool\n",
    "def visit_url(url: str):\n",
    "    \"\"\"Visit a URL and return the content.\n",
    "    \n",
    "    Long description of the function.\n",
    "    \n",
    "    Args:\n",
    "        url (str): The URL to visit.\n",
    "        \n",
    "    Returns:\n",
    "        str: The content of the URL.\n",
    "    \"\"\"\n",
    "    import requests\n",
    "\n",
    "    response = requests.get(url)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function can be decorated by `ArkTool` to be a tool, which can be invoked by Ark agent. The docstring of function is important, as its name, description and arguments will be sent to the model. The detailed docstring usage can be found [here]().\n",
    "\n",
    "### Equip to agent\n",
    "\n",
    "The created tool can be equipped to an agent with just only one option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkintelligence.agent import ArkAgent\n",
    "\n",
    "agent = ArkAgent(\n",
    "    name=\"Web search assistant\",\n",
    "    model=\"doubao-1-5-pro-256k-250115\",\n",
    "    tools=['visit_url'],\n",
    ")\n",
    "\n",
    "response = agent.run(\"What is the latest news about ArkIntelligence?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG\n",
    "\n",
    "RAG enhances model response. In Ark, we provide concise method to enbale RAG.\n",
    "\n",
    "### Knowledge base\n",
    "\n",
    "You can create a knowledge base with your local files like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkintelligence.knowledgebase import ArkKnowledgeBase\n",
    "\n",
    "kb = ArkKnowledgeBase(\n",
    "    name=\"ArkIntelligence\",\n",
    "    description=\"ArkIntelligence is a company that provides AI solutions.\",\n",
    "    data=data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During creation, your data will be uploaded to Ark platform and processed by embedding models such as `doubao-embed` (embed model API can be found [here]()). The processed data is stored in your local memory rather than cloud space.\n",
    "\n",
    "### Equip to agent\n",
    "\n",
    "Equip the knowledge base to your agent like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ArkAgent(\n",
    "    name=\"Knowledge base agent\",\n",
    "    model=\"deepseek-v3-250324\",\n",
    "    prompt=\"You are a helpful assistant.\",\n",
    "    knowldgebase=kb,\n",
    ")\n",
    "res = agent.run(\"Summary the pros and cons of SmartVM\")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Awesome samples\n",
    "\n",
    "## Auto-summary\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arkintelligence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
