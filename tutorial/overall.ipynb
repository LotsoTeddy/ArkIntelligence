{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "A freshman-friendly tutorial for Ark platform.\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Why Ark?\n",
    "\n",
    "Ark is a platform that supports multiple kinds of models running.\n",
    "\n",
    "### Productions\n",
    "\n",
    "Productions in ARK, including models, agents and something else.\n",
    "\n",
    "### Rodemap\n",
    "\n",
    "Rodemap and primary changelog of Ark.\n",
    "\n",
    "## Set-up\n",
    "\n",
    "### Installation\n",
    "\n",
    "Install Ark SDK from Github repository:\n",
    "\n",
    "> We use Githubfast mirror here to accelerate github clone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install git+https://githubfast.com/LotsoTeddy/ArkIntelligence.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication\n",
    "\n",
    "Go to https://www.example.com to generate your API key, and set it in your code or environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"ARK_API_KEY\"] = \"your_ark_api_key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can chat with a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkintelligence.model import ArkModel\n",
    "\n",
    "model = ArkModel(model=\"doubao-1.5-pro-32k-250115\")\n",
    "\n",
    "response = model.chat(prompt=\"Who are you?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you can create a Translator agent to translate your text from English to Chinese:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkintelligence.agent import ArkAgent\n",
    "\n",
    "agent = ArkAgent(\n",
    "    name=\"Translator\",\n",
    "    model=\"doubao-1.5-pro-32k-250115\",\n",
    "    prompt=\"Translate the input text from English to Chinese.\",\n",
    ")\n",
    "\n",
    "res = agent.run(\"Inspire Creativity, Enrich Life!\")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic usage\n",
    "\n",
    "## Overview\n",
    "\n",
    "The entire list of model ID can be found [here](). The capabilities of each model is listed as follows:\n",
    "\n",
    "| Model ID      | Image understanding | Video generation | Function calling | \n",
    "| - | - | - | - |\n",
    "| doubao-1.5-vision-pro-32k-250115 | ✅ | | |\n",
    "| doubao-seaweed-241128 | | ✅ | |\n",
    "\n",
    "## Text capabilities\n",
    "\n",
    "### Simple chat\n",
    "\n",
    "Single-turn completion has no memory, so the previous user chat will not stored during chat. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkintelligence.model import ArkModel\n",
    "\n",
    "model = ArkModel(model=\"doubao-1.5-pro-32k-250115\")\n",
    "\n",
    "response = model.chat(prompt=\"Your name is ArkIntelligence.\")\n",
    "print(response)\n",
    "\n",
    "response = model.chat(prompt=\"What is your name?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat with memory\n",
    "\n",
    "Multi-turn chat has memory, the model can remember the history messages by setting `enable_context=True` during initialization. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkintelligence.model import ArkModel\n",
    "\n",
    "model = ArkModel(\n",
    "    model=\"doubao-1.5-pro-32k-250115\",\n",
    "    enbale_context=True # Make LLM remember the context\n",
    "    )\n",
    "\n",
    "response = model.chat(prompt=\"Your name is ArkIntelligence.\")\n",
    "print(response)\n",
    "\n",
    "response = model.chat(prompt=\"What is your name?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can remember the previous user input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision capabilities\n",
    "\n",
    "Ark provides capabilities about multi-media, such as vision and sounds. Here we introduce the vision-related demos.\n",
    "\n",
    "### Image understanding\n",
    "\n",
    "We use LLM to understand the following image:\n",
    "\n",
    "<img src='https://ark-tutorial.tos-cn-beijing.volces.com/assets/images/cat.png' style='width:150px'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkintelligence.model import ArkModel\n",
    "\n",
    "IMAGE_PATH = \"./assets/images/cat.png\"\n",
    "model = ArkModel(\n",
    "    model=\"doubao-1.5-vision-pro-32k-250115\",  # Use vision model here\n",
    ")\n",
    "\n",
    "response = model.chat(\n",
    "    prompt=\"Please describe this image with details.\",\n",
    "    attachment=IMAGE_PATH,\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video generation\n",
    "\n",
    "We use doubao to generate a video according to a static image and prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REF_IMAGE_PATH = \"./assets/images/cat.png\"\n",
    "model = ArkModel(\n",
    "    model=\"doubao-seaweed-241128\",  # Use video generation model here\n",
    ")\n",
    "\n",
    "response = model.generate_video(\n",
    "    prompt=\"Please generate a video with a cat running.\",\n",
    "    attachment=REF_IMAGE_PATH,\n",
    ") # This will take a while\n",
    "\n",
    "print(\"Waiting for video generation...\")\n",
    "print(\"Generated video url is: \" + response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> Want to make the video more vivid? Maybe you need: prompt refine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent\n",
    "\n",
    "## A minimal agent\n",
    "\n",
    "A simple agent can be built with several lines. The `name` field is not necessary, but provide it will make agent more intelligent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkintelligence.agent import ArkAgent\n",
    "\n",
    "agent = ArkAgent(\n",
    "    name=\"Meeting assistant\",\n",
    "    model=\"deepseek-v3-250324\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can chat with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.run(\"Who are you?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A complex agent with several capabilities (such as knowledge base and function calling) just needs more 2 lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduce what the agent is.\n",
    "\n",
    "## Prompt engineering\n",
    "\n",
    "Prompt engineering is important that can make your prompt more rich and useful for models.\n",
    "\n",
    "### Prompt usage\n",
    "\n",
    "Prompt can be used for interacting with models. The models understand your prompt and give responses. For example, with a prompt, a complex English statement can be optimized to be more concise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkintelligence.model import ArkModel\n",
    "\n",
    "model = ArkModel(\n",
    "    model=\"doubao-1.5-pro-32k-250115\",\n",
    "    enbale_context=True,\n",
    ")\n",
    "\n",
    "response = model.chat(\n",
    "    prompt=\"I will give you a sentence, please make the sentence more concise and elegant.\"\n",
    ")\n",
    "print(response)\n",
    "\n",
    "response = model.chat(\n",
    "    prompt=\"In a Chinese house, the kitchen is only a place for cooking things; but in many Western houses, the kitchen is not only a place where people cook meals and eat them but also a place where the family members or friends usually meet each other.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt refine\n",
    "\n",
    "Refine prompts is important, the comparision is as follows. We use a simple and a refined prompt to generate images, then compare the image quality.\n",
    "\n",
    "You can build an agent to refine prompt: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkintelligence.agent import ArkAgent\n",
    "\n",
    "prompt = \"Draw a cute golden british shorthair cat.\"\n",
    "\n",
    "refine_agent = ArkAgent(\n",
    "    name=\"Prompt refine assistant\",\n",
    "    model=\"doubao-1-5-pro-256k-250115\",\n",
    "    prompt=\"Refine the prompt to make it more suitable for image generation.\",\n",
    ")\n",
    "prompt_refined = refine_agent.run(prompt)\n",
    "\n",
    "print(f\"Original prompt:\\n{prompt}\")\n",
    "print(f\"Refined prompt:\\n{prompt_refined}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the two prompts to generate videos and see the differents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkintelligence.model import ArkModel\n",
    "\n",
    "model = ArkModel(\n",
    "    model=\"doubao-seaweed-241128\",  # Use video generation model here\n",
    ")\n",
    "\n",
    "video = model.generate_video(\n",
    "    prompt=prompt,\n",
    ")\n",
    "video_with_refine = model.generate_video(\n",
    "    prompt=prompt_refined,\n",
    ")\n",
    "\n",
    "print(f'Original video url is: {video}')\n",
    "print(f'Refined video url is: {video_with_refine}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function calling\n",
    "\n",
    "\n",
    "\n",
    "### Tool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arkintelligence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
