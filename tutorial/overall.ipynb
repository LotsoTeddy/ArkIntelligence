{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LotsoTeddy/ArkIntelligence/blob/master/tutorial/overall.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG33oR-V0u25"
      },
      "source": [
        "<hr/>\n",
        "<img src=\"https://portal.volccdn.com/obj/volcfe/logo/appbar_logo_dark.2.svg?sanitize=true\" align=center>\n",
        "<hr/>\n",
        "\n",
        "# Introduction\n",
        "\n",
        "Volengine Ark provides you with a development platform for large model services, offering feature-rich, secure and price-competitive model calling services, as well as end-to-end functions such as model data, fine-tuning, reasoning, evaluation, and so on, to comprehensively guarantee your AI application development landing.\n",
        "\n",
        "This is a freshman-friendly tutorial for Ark SDK, which helps you to build your own intelligent applications through agent, knowledge base, and so on.\n",
        "\n",
        "## Overview\n",
        "\n",
        "### Why Ark?\n",
        "\n",
        "Ark is a platform that supports multiple kinds of models running. Ark has the following advantages:\n",
        "\n",
        "- **Security and Mutual Trust**: Large model security and trust program strictly protects the model and information security of model providers and model users, click to view the white paper on security and mutual trust.\n",
        "- **Selected Models**: Supporting multi-industry models for various business scenarios, providing rich platform applications and tools to help you build your own innovative scenarios.\n",
        "- **Strong Arithmetic Power**: Based on the volcano's Wanka resource pool, we provide sufficient high-performance GPU resources to provide you with end-to-end modeling services including model fine-tuning, evaluation, and inference.\n",
        "- **Enterprise-level services**: provide professional service system support, professional product operation and sales delivery services to meet the needs of enterprise application construction and delivery.\n",
        "\n",
        "### Productions\n",
        "\n",
        "Productions in ARK, including models, agents and something else. The specific productions are shown in the following image.\n",
        "\n",
        "![productions](https://ark-tutorial.tos-cn-beijing.volces.com/assets/images/productions.png)\n",
        "\n",
        "\n",
        "### Rodemap\n",
        "\n",
        "Rodemap and primary changelog of Ark.\n",
        "\n",
        "- 2025-03-31: foo\n",
        "- 2025-03-30: bar\n",
        "\n",
        "## Setup\n",
        "\n",
        "### Installation\n",
        "\n",
        "Install ArkIntelligence SDK from Github repository:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0T9598P80u26"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/LotsoTeddy/ArkIntelligence.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILGi2_YG0u26"
      },
      "source": [
        "### Authentication\n",
        "\n",
        "Go to [this doc](https://www.volcengine.com/docs/82379/1399008#b00dee71) to learn how to generate your API key, and set it in your code or environment variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "r8IXRcOG0u26"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"ARK_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quEtH1_k0u26"
      },
      "source": [
        "## Quickstart\n",
        "\n",
        "You can chat with a model to learn the model's information:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IdDzL7NZ0u26",
        "outputId": "01d7d9ae-c2b5-4ff6-bea5-0b605170a1cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response from model:\n",
            "\n",
            "I'm Doubao, an AI developed by ByteDance. I'm here to have conversations with you, answer a wide variety of questions, offer useful information, and help you in many ways. Whether it's about history, science, technology, or just having a casual chat, feel free to tell me what's on your mind! \n"
          ]
        }
      ],
      "source": [
        "from arkintelligence.model import ArkModel\n",
        "\n",
        "model = ArkModel(model=\"doubao-1.5-pro-32k-250115\")\n",
        "\n",
        "response = model.chat(prompt=\"Who are you?\")\n",
        "\n",
        "print('Response from model:\\n')\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzNUWEfS0u27"
      },
      "source": [
        "Or, you can create an agent (named by Translator) for translating your text from *English* to *Chinese*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-na7hpMK0u27",
        "outputId": "7c01c26b-d955-4da9-f509-ad454672d4b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated text from agent:\n",
            "\n",
            "ÊøÄÂèëÂàõÊÑèÔºå‰∏∞ÂØåÁîüÊ¥ªÔºÅ\n"
          ]
        }
      ],
      "source": [
        "from arkintelligence.agent import ArkAgent\n",
        "\n",
        "agent = ArkAgent(\n",
        "    name=\"Translator\",\n",
        "    model=\"doubao-1.5-pro-32k-250115\",\n",
        "    prompt=\"Translate the input text from English to Chinese.\",\n",
        ")\n",
        "\n",
        "response = agent.run(\"Inspire Creativity, Enrich Life!\")\n",
        "\n",
        "print('Translated text from agent:\\n')\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7XyOQM30u27"
      },
      "source": [
        "# Basic usage\n",
        "\n",
        "## Overview\n",
        "\n",
        "The entire list of model ID can be found [here](https://www.volcengine.com/docs/82379/1330310). The capabilities of each model is listed as follows:\n",
        "\n",
        "| Model ID      | Image understanding | Video generation | Function calling |\n",
        "| - | - | - | - |\n",
        "| doubao-1.5-vision-pro-32k-250115 | ‚úÖ | | |\n",
        "| doubao-seaweed-241128 | | ‚úÖ | |\n",
        "| ... | | | |\n",
        "\n",
        "## Text capabilities\n",
        "\n",
        "### Chat\n",
        "\n",
        "A simplest chat is in the form of single-turn, which has no memory. The history messages whether from user or model will not be saved. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CgT1DSPH0u27",
        "outputId": "f183cb94-8620-4a1c-890d-b4227fbc75ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response from the first chat:\n",
            "\n",
            "Got it! From now on, my name is ArkIntelligence. Nice to meet you!\n",
            "\n",
            "\n",
            "Response from the second chat:\n",
            "\n",
            "I don't remember the last prompt as I don't have a memory of previous interactions in that way. My name is Doubao. \n"
          ]
        }
      ],
      "source": [
        "from arkintelligence.model import ArkModel\n",
        "\n",
        "model = ArkModel(model=\"doubao-1.5-pro-32k-250115\")\n",
        "\n",
        "res1 = model.chat(prompt=\"Your name is ArkIntelligence.\")\n",
        "res2 = model.chat(prompt=\"Do you remember the last prompt? What is your name?\")\n",
        "\n",
        "print('Response from the first chat:\\n')\n",
        "print(res1)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print('Response from the second chat:\\n')\n",
        "print(res2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above code, the first chat sets a name for the model, but this message is not saved, hence the second chat will not return the preset name."
      ],
      "metadata": {
        "id": "K_S5v1-36CT3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gpFnnfV0u27"
      },
      "source": [
        "### Chat with memory\n",
        "\n",
        "Sometimes you need a multiple turn chatting, you can enable history message saving by setting `enable_context=True` during model initialization. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Dy8IJ2vI0u27",
        "outputId": "12cf611b-2d36-4a6b-adf2-c3eff2a93b0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response from the first chat:\n",
            "\n",
            "Thank you for naming me ArkIntelligence. I'll do my best to assist you with all your queries!\n",
            "\n",
            "\n",
            "Response from the second chat:\n",
            "\n",
            "My name is ArkIntelligence. I remember your previous prompt where you assigned this name to me. \n"
          ]
        }
      ],
      "source": [
        "from arkintelligence.model import ArkModel\n",
        "\n",
        "model = ArkModel(\n",
        "    model=\"doubao-1.5-pro-32k-250115\",\n",
        "    enbale_context=True # Make the model remember the context\n",
        "    )\n",
        "\n",
        "res1 = model.chat(prompt=\"Your name is ArkIntelligence.\")\n",
        "res2 = model.chat(prompt=\"Do you remember the last prompt? What is your name?\")\n",
        "\n",
        "print('Response from the first chat:\\n')\n",
        "print(res1)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print('Response from the second chat:\\n')\n",
        "print(res2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5ntuS7B0u27"
      },
      "source": [
        "The model can remember the previous user inputs. The context will be managed automatically in ArkIntelligence!\n",
        "\n",
        "### Chat with attachment [WIP]\n",
        "\n",
        "We support upload your single file with format of `.txt`, for example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwvyrYsV0u27"
      },
      "outputs": [],
      "source": [
        "# ======== [WIP] ========\n",
        "# from arkintelligence.model import ArkModel\n",
        "\n",
        "# model = ArkModel(model=\"doubao-1.5-pro-32k-250115\")\n",
        "\n",
        "# response = model.chat(\n",
        "#     prompt=\"Your name is ArkIntelligence.\",\n",
        "#     attachment=\"FILE_PATH\",  # TODO(LotsoTeddy): Parsing attachment\n",
        "# )\n",
        "# response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGIgSZBa0u27"
      },
      "source": [
        "## Vision capabilities\n",
        "\n",
        "Ark provides capabilities about multi-media, such as vision and sounds. Here we introduce the vision-related demos. The vision-related task is devided into image understanding and video generation.\n",
        "\n",
        "- **Image understanding**: this task can read information from one or several images and return the content to the user\n",
        "- **Video generation**: this task can generate video from text and images\n",
        "\n",
        "### Image understanding\n",
        "\n",
        "We use the model `doubao-1.5-vision-pro-32k-250115` to understand the following image:\n",
        "\n",
        "<img src='https://ark-tutorial.tos-cn-beijing.volces.com/assets/images/cat.png' style='width:100px'>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Vk9lq6bB0u27",
        "outputId": "2bd191d6-a2ed-41cb-c148-78ec089e67e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "File path ./assets/images/cat.png is not valid.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-e44d7391c1f3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m response = model.process_image(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Please describe this image with details.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mattachment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMAGE_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/arkintelligence/model/ArkModel.py\u001b[0m in \u001b[0;36mprocess_image\u001b[0;34m(self, prompt, attachment)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0m_attachment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mattachment\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattachment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mattachment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_attachment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                     logger.error(\n\u001b[1;32m     66\u001b[0m                         \u001b[0;34mf\"Attachment is not an image, please check the file path.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/arkintelligence/utils/misc.py\u001b[0m in \u001b[0;36mis_image\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Validate the file path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"File path {file_path} is not valid.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m# List of valid image extensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mvalid_extensions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".jpeg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".gif\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".bmp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".tiff\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: File path ./assets/images/cat.png is not valid."
          ]
        }
      ],
      "source": [
        "from arkintelligence.model import ArkModel\n",
        "\n",
        "IMAGE_PATH = \"./assets/images/cat.png\"\n",
        "model = ArkModel(\n",
        "    model=\"doubao-1.5-vision-pro-32k-250115\",  # Use vision model here\n",
        ")\n",
        "\n",
        "response = model.process_image(\n",
        "    prompt=\"Please describe this image with details.\",\n",
        "    attachment=IMAGE_PATH,\n",
        ")\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kycGTtYd0u27"
      },
      "source": [
        "### Video generation\n",
        "\n",
        "We use `doubao` model to generate a video according to a static image and prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eC7f0ipR0u27"
      },
      "outputs": [],
      "source": [
        "REF_IMAGE_PATH = \"./assets/images/cat.png\"\n",
        "model = ArkModel(\n",
        "    model=\"doubao-seaweed-241128\",  # Use video generation model here\n",
        ")\n",
        "\n",
        "response = model.generate_video(\n",
        "    prompt=\"Please generate a video with a cat running.\",\n",
        "    attachment=REF_IMAGE_PATH,\n",
        ") # This will take a while\n",
        "\n",
        "print(\"Waiting for video generation...\")\n",
        "print(\"Generated video url is: \" + response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYcHPock0u27"
      },
      "source": [
        "\n",
        "\n",
        "> Want to make the video more vivid? Maybe you need: prompt refine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqWSml5i0u28"
      },
      "source": [
        "# Agent\n",
        "\n",
        "## A minimal agent\n",
        "\n",
        "A simple agent can be built with several lines. The `name` field is not necessary, but provide it will make agent more intelligent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejpD_lRz0u28"
      },
      "outputs": [],
      "source": [
        "from arkintelligence.agent import ArkAgent\n",
        "\n",
        "agent = ArkAgent(\n",
        "    name=\"Meeting assistant\",\n",
        "    model=\"deepseek-v3-250324\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqEpIpze0u28"
      },
      "source": [
        "Then you can chat with it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cqz2hfXy0u28",
        "outputId": "857e26f4-6645-4d82-a71f-898db9b469ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"I'm your **Meeting Assistant**, here to help you with anything related to meetings‚Äîwhether it's scheduling, note-taking, summarizing discussions, setting agendas, or following up on action items.  \\n\\nHow can I assist you today? üòä\""
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = agent.run(\"Who are you?\")\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVEZlufi0u28"
      },
      "source": [
        "A complex agent with several capabilities (such as knowledge base and function calling) just needs more 2 lines:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NM6gJvC40u28"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8OCLym00u28"
      },
      "source": [
        "Introduce what the agent is.\n",
        "\n",
        "## Prompt engineering\n",
        "\n",
        "Prompt engineering is important that can make your prompt more rich and useful for models.\n",
        "\n",
        "### Prompt usage\n",
        "\n",
        "Prompt can be used for interacting with models. The models understand your prompt and give responses. For example, with a prompt, a complex English statement can be optimized to be more concise:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1qrs9s10u28",
        "outputId": "8319af3d-5ca2-4798-bdad-c9205e067d91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sure! Please provide the sentence, and I'll do my best to make it more concise and elegant.\n",
            "In Chinese houses, the kitchen serves solely for cooking. However, in many Western homes, it's not just a cooking and dining area but also a gathering place for family and friends. \n"
          ]
        }
      ],
      "source": [
        "from arkintelligence.model import ArkModel\n",
        "\n",
        "model = ArkModel(\n",
        "    model=\"doubao-1.5-pro-32k-250115\",\n",
        "    enbale_context=True,\n",
        ")\n",
        "\n",
        "response = model.chat(\n",
        "    prompt=\"I will give you a sentence, please make the sentence more concise and elegant.\"\n",
        ")\n",
        "print(response + '\\n')\n",
        "\n",
        "response = model.chat(\n",
        "    prompt=\"In a Chinese house, the kitchen is only a place for cooking things; but in many Western houses, the kitchen is not only a place where people cook meals and eat them but also a place where the family members or friends usually meet each other.\"\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2nZWUb70u28"
      },
      "source": [
        "### Prompt refine\n",
        "\n",
        "Refine prompts is important, the comparision is as follows. We use a simple and a refined prompt to generate images, then compare the image quality.\n",
        "\n",
        "You can build an agent to refine prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_21pcLI0u28",
        "outputId": "f628da1f-bc2e-44cc-da22-852d525e1226"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original prompt:\n",
            "Draw a cute golden british shorthair cat.\n",
            "Refined prompt:\n",
            "Create an image of an adorable Golden British Shorthair cat. Focus on the cat's round face, big, bright eyes, short and plush fur with a warm golden hue. Include details like the cat's small, rounded ears, a slightly chubby body, and its soft paws. The cat could be in a relaxed pose, perhaps sitting or lying down, with an expression that exudes cuteness and charm. Consider adding a simple, cozy background like a soft blanket or a sunny corner of a room to enhance the overall appealing and endearing atmosphere. \n"
          ]
        }
      ],
      "source": [
        "from arkintelligence.agent import ArkAgent\n",
        "\n",
        "prompt = \"Draw a cute golden british shorthair cat.\"\n",
        "\n",
        "refine_agent = ArkAgent(\n",
        "    name=\"Prompt refine assistant\",\n",
        "    model=\"doubao-1-5-pro-256k-250115\",\n",
        "    prompt=\"Refine the prompt to make it more suitable for image generation.\",\n",
        ")\n",
        "prompt_refined = refine_agent.run(prompt)\n",
        "\n",
        "print(f\"Original prompt:\\n{prompt}\")\n",
        "print(f\"Refined prompt:\\n{prompt_refined}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTogTxvV0u28"
      },
      "source": [
        "Then we use the two prompts to generate videos and see the differents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KORB226K0u28"
      },
      "outputs": [],
      "source": [
        "from arkintelligence.model import ArkModel\n",
        "\n",
        "model = ArkModel(\n",
        "    model=\"doubao-seaweed-241128\",  # Use video generation model here\n",
        ")\n",
        "\n",
        "video = model.generate_video(\n",
        "    prompt=prompt,\n",
        ")\n",
        "video_with_refine = model.generate_video(\n",
        "    prompt=prompt_refined,\n",
        ")\n",
        "\n",
        "print(f'Original video url is: {video}')\n",
        "print(f'Refined video url is: {video_with_refine}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB6KcEvV0u28"
      },
      "source": [
        "### Equip to agent\n",
        "\n",
        "You can enable prompt refine in your agent, the agent will automatically refine your **first** prompt with a default refine prompt (you can modify this by pass `refine_prompt`). The usage is as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IZDBjdl0u28"
      },
      "outputs": [],
      "source": [
        "from arkintelligence.agent import ArkAgent\n",
        "\n",
        "prompt = \"Draw a cute golden british shorthair cat.\"\n",
        "\n",
        "refine_agent = ArkAgent(\n",
        "    name=\"Prompt refine assistant\",\n",
        "    model=\"doubao-1-5-pro-256k-250115\",\n",
        "    prompt=\"Refine the prompt to make it more suitable for image generation.\",\n",
        "    refine_requirement=\"Refine the prompt to make it more suitable for image generation.\",\n",
        ")\n",
        "prompt_refined = refine_agent.run(prompt)\n",
        "\n",
        "print(f\"Original prompt:\\n{prompt}\")\n",
        "print(f\"Refined prompt:\\n{prompt_refined}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P1okD4n0u28"
      },
      "source": [
        "## Function calling\n",
        "\n",
        "The Ark agent can call your local function to finish your task.\n",
        "\n",
        "### Tool\n",
        "\n",
        "Before init an agent, you should create a tool (which is a Python function) to define tool logic. For example, we provide a `visit_url` here to read the website information:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBRiXznW0u28"
      },
      "outputs": [],
      "source": [
        "from arkintelligence.tool import ArkTool\n",
        "\n",
        "@ArkTool\n",
        "def visit_url(url: str):\n",
        "    \"\"\"Visit a URL and return the content.\n",
        "\n",
        "    Long description of the function.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL to visit.\n",
        "\n",
        "    Returns:\n",
        "        str: The content of the URL.\n",
        "    \"\"\"\n",
        "    import requests\n",
        "\n",
        "    response = requests.get(url)\n",
        "    return response.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7m7weHn0u28"
      },
      "source": [
        "A function can be decorated by `ArkTool` to be a tool, which can be invoked by Ark agent. The docstring of function is important, as its name, description and arguments will be sent to the model. The detailed docstring usage can be found [here]().\n",
        "\n",
        "### Equip to agent\n",
        "\n",
        "The created tool can be equipped to an agent with just only one option:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxAHNWEl0u28"
      },
      "outputs": [],
      "source": [
        "from arkintelligence.agent import ArkAgent\n",
        "\n",
        "agent = ArkAgent(\n",
        "    name=\"Web search assistant\",\n",
        "    model=\"doubao-1-5-pro-256k-250115\",\n",
        "    tools=['visit_url'],\n",
        ")\n",
        "\n",
        "response = agent.run(\"What is the latest news about ArkIntelligence?\")\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-ZC3WfA0u28"
      },
      "source": [
        "## RAG\n",
        "\n",
        "RAG enhances model response. In Ark, we provide concise method to enbale RAG.\n",
        "\n",
        "### Knowledge base\n",
        "\n",
        "You can create a knowledge base with your local files like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATH0cDxq0u28"
      },
      "outputs": [],
      "source": [
        "from arkintelligence.knowledgebase import ArkKnowledgeBase\n",
        "\n",
        "kb = ArkKnowledgeBase(\n",
        "    name=\"ArkIntelligence\",\n",
        "    description=\"ArkIntelligence is a company that provides AI solutions.\",\n",
        "    data=data\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rXAIUjh0u28"
      },
      "source": [
        "During creation, your data will be uploaded to Ark platform and processed by embedding models such as `doubao-embed` (embed model API can be found [here]()). The processed data is stored in your local memory rather than cloud space.\n",
        "\n",
        "### Equip to agent\n",
        "\n",
        "Equip the knowledge base to your agent like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Afk8aV2O0u28"
      },
      "outputs": [],
      "source": [
        "agent = ArkAgent(\n",
        "    name=\"Knowledge base agent\",\n",
        "    model=\"deepseek-v3-250324\",\n",
        "    prompt=\"You are a helpful assistant.\",\n",
        "    knowldgebase=kb,\n",
        ")\n",
        "res = agent.run(\"Summary the pros and cons of SmartVM\")\n",
        "res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjGbBt6h0u29"
      },
      "source": [
        "# Awesome samples\n",
        "\n",
        "## Auto-summary\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "arkintelligence",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}